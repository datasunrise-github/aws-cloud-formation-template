AWSTemplateFormatVersion: 2010-09-09
Description: DataSunrise Database and Data Security - Network Load Balancer universal template
Mappings:
  RegionMap:
    eu-central-1:
      AMI: ami-0aeb375cce749536e
    eu-north-1:
      AMI: ami-00999eddd50739916
    ap-south-1:
      AMI: ami-0658895f38b83c779
    eu-west-3:
      AMI: ami-0f27ef394d90a6fb6
    eu-west-2:
      AMI: ami-070babfa4e5bca30a
    eu-west-1:
      AMI: ami-0a9326fe54ccef3f0
    ap-northeast-2:
      AMI: ami-08ed29503b4713273
    me-south-1:
      AMI: ami-0a093ba98bb368be0
    ap-northeast-1:
      AMI: ami-070716e56cb72af8b
    sa-east-1:
      AMI: ami-08a1814b3bc7ab2fa
    ca-central-1:
      AMI: ami-07fd276455d7b144a
    ap-east-1:
      AMI: ami-05d80226641ffd884
    ap-southeast-1:
      AMI: ami-087853e7c207c8653
    ap-southeast-2:
      AMI: ami-0981f4035d42ec7c9
    us-east-1:
      AMI: ami-0482b475be4b30f1a
    us-east-2:
      AMI: ami-09265faf98f36bcb4
    us-west-1:
      AMI: ami-01c6e8d1152b9e0c2
    us-west-2:
      AMI: ami-06d1ca08c9c6627d6
  Consts:
    V1:
      AMIProductCode: e4d3d3b6266ocd12it8gny7gh
      CARProductCode: 88q6e9h0zcpo4hpvxrxtlglgd
      DSCloudWatchEventSource: DataSunrise
      DSRoot: /opt/datasunrise
      DSCloudRoot: /opt/ds-cloud
      BackupUploadLog: /tmp/backup-upload.log
      BackupTempDir: /tmp/ds-backups
      AliveMetricName: ServiceAlive
      AliveMetricNamespace: DataSunrise
      AliveMetricLog: /tmp/send-alive.log
      LoadBalancerIdleTimeout: '3600'
      pgPort: '5432'
      myPort: '3306'
      msPort: '1433'
      AuditInternalParameterPg: '1'
      AuditInternalParameterMy: '2'
      AuditInternalParameterMs: '6'
      DictionaryInternalParameterPg: postgresql
      DictionaryInternalParameterMy: mysql
      DictionaryInternalParameterMs: mssql
      DictionaryEnginePg: postgres
      DictionaryEngineMy: mysql
      DictionaryEngineMs: sqlserver-se
      AuditEnginePg: postgres
      AuditEngineMy: mysql
      AuditEngineMs: sqlserver-se
      EngineVersionPg: '14'
      EngineVersionMy: '5.7'
      EngineVersionMs: '14.00'
      AuditAuroraEnginePg: aurora-postgresql
      AuditAuroraEngineMy: aurora-mysql
      AuditAuroraEngineVersionPg: '13'
      AuditAuroraEngineVersionMy: '5.7'
      ParameterGroupFamilyPg: 'postgres14'
      ParameterGroupFamilyMy: 'MySQL5.7'
      DictionaryParameterGroupFamilyMs: 'sqlserver-se-14.0'
      AuditParameterGroupFamilyMs: 'sqlserver-se-14.0'
      ParameterGroupFamilyPgCluster: aurora-postgresql13
      ParameterGroupFamilyMyCluster: aurora-mysql5.7
      PostgresLicenseModel: 'postgresql-license'
      MysqlLicenseModel: 'general-public-license'
      MssqlLicenseModel: 'license-included'
Parameters:
  DirectoryServiceId:
    Description: Prefered AWS AD Id. Must belong mentioned VPC.
    Type: String
  ADLogin:
    Description: The AD user login that may join to AD
    Type: String
  ADPassword:
    NoEcho: 'true'
    Type: String
  ADCIDR:
    Description: IP address range that can be used access AD ports, look at https://docs.aws.amazon.com/directoryservice/latest/admin-guide/ms_ad_tutorial_setup_trust_prepare_mad.html
    Type: String
  TimeZone:
    Type: String
    Default: America/Los_Angeles
    AllowedValues:
      - Africa/Lagos
      - Africa/Mogadishu
      - Africa/Monrovia
      - Africa/Nairobi
      - Africa/Tripoli
      - Africa/Tunis
      - America/Anchorage
      - America/Argentina/Buenos_Aires
      - America/Argentina/San_Juan
      - America/Argentina/San_Luis
      - America/Aruba
      - America/Asuncion
      - America/Atikokan
      - America/Bahia
      - America/Bahia_Banderas
      - America/Barbados
      - America/Belem
      - America/Belize
      - America/Blanc-Sablon
      - America/Boa_Vista
      - America/Bogota
      - America/Boise
      - America/Cambridge_Bay
      - America/Campo_Grande
      - America/Cancun
      - America/Caracas
      - America/Cayenne
      - America/Cayman
      - America/Chicago
      - America/Chihuahua
      - America/Costa_Rica
      - America/Creston
      - America/Cuiaba
      - America/Curacao
      - America/Danmarkshavn
      - America/Dawson
      - America/Dawson_Creek
      - America/Denver
      - America/Detroit
      - America/Dominica
      - America/Edmonton
      - America/Eirunepe
      - America/El_Salvador
      - America/Fort_Nelson
      - America/Fortaleza
      - America/Glace_Bay
      - America/Goose_Bay
      - America/Grand_Turk
      - America/Grenada
      - America/Guadeloupe
      - America/Guatemala
      - America/Guayaquil
      - America/Guyana
      - America/Halifax
      - America/Havana
      - America/Hermosillo
      - America/Indiana/Indianapolis
      - America/Indiana/Knox
      - America/Indiana/Marengo
      - America/Indiana/Petersburg
      - America/Indiana/Tell_City
      - America/Indiana/Vevay
      - America/Indiana/Vincennes
      - America/Indiana/Winamac
      - America/Inuvik
      - America/Iqaluit
      - America/Jamaica
      - America/Juneau
      - America/Kentucky/Louisville
      - America/Kentucky/Monticello
      - America/Kralendijk
      - America/La_Paz
      - America/Lima
      - America/Los_Angeles
      - America/Lower_Princes
      - America/Maceio
      - America/Managua
      - America/Manaus
      - America/Marigot
      - America/Martinique
      - America/Matamoros
      - America/Mazatlan
      - America/Menominee
      - America/Merida
      - America/Metlakatla
      - America/Mexico_City
      - America/Miquelon
      - America/Moncton
      - America/Monterrey
      - America/Montevideo
      - America/Montserrat
      - America/Nassau
      - America/New_York
      - America/Nipigon
      - America/Nome
      - America/Noronha
      - America/North_Dakota/Beulah
      - America/North_Dakota/Center
      - America/North_Dakota/New_Salem
      - America/Nuuk
      - America/Ojinaga
      - America/Panama
      - America/Pangnirtung
      - America/Paramaribo
      - America/Phoenix
      - America/Port-au-Prince
      - America/Port_of_Spain
      - America/Porto_Velho
      - America/Puerto_Rico
      - America/Punta_Arenas
      - America/Rainy_River
      - America/Rankin_Inlet
      - America/Recife
      - America/Regina
      - America/Resolute
      - America/Rio_Branco
      - America/Santarem
      - America/Santiago
      - America/Santo_Domingo
      - America/Sao_Paulo
      - America/Scoresbysund
      - America/Sitka
      - America/St_Barthelemy
      - America/St_Johns
      - America/St_Kitts
      - America/St_Lucia
      - America/St_Thomas
      - America/St_Vincent
      - America/Swift_Current
      - America/Tegucigalpa
      - America/Thule
      - America/Thunder_Bay
      - America/Tijuana
      - America/Toronto
      - America/Tortola
      - America/Vancouver
      - America/Whitehorse
      - America/Winnipeg
      - America/Yakutat
      - America/Yellowknife
      - Asia/Dubai
      - Asia/Hong_Kong
      - Asia/Jerusalem
      - Asia/Kuwait
      - Asia/Qatar
      - Asia/Seoul
      - Asia/Shanghai
      - Asia/Singapore
      - Asia/Tokyo
      - Atlantic/Azores
      - Atlantic/Bermuda
      - Atlantic/Canary
      - Atlantic/Cape_Verde
      - Atlantic/Faroe
      - Atlantic/Madeira
      - Atlantic/Reykjavik
      - Atlantic/South_Georgia
      - Atlantic/St_Helena
      - Atlantic/Stanley
      - Australia/Adelaide
      - Australia/Brisbane
      - Australia/Broken_Hill
      - Australia/Currie
      - Australia/Darwin
      - Australia/Eucla
      - Australia/Hobart
      - Australia/Lindeman
      - Australia/Lord_Howe
      - Australia/Melbourne
      - Australia/Perth
      - Australia/Sydney
      - Europe/Amsterdam
      - Europe/Andorra
      - Europe/Athens
      - Europe/Belgrade
      - Europe/Berlin
      - Europe/Bratislava
      - Europe/Brussels
      - Europe/Bucharest
      - Europe/Budapest
      - Europe/Busingen
      - Europe/Chisinau
      - Europe/Copenhagen
      - Europe/Dublin
      - Europe/Gibraltar
      - Europe/Guernsey
      - Europe/Helsinki
      - Europe/Isle_of_Man
      - Europe/Istanbul
      - Europe/Jersey
      - Europe/Kiev
      - Europe/Lisbon
      - Europe/Ljubljana
      - Europe/London
      - Europe/Luxembourg
      - Europe/Madrid
      - Europe/Malta
      - Europe/Mariehamn
      - Europe/Minsk
      - Europe/Monaco
      - Europe/Moscow
      - Europe/Oslo
      - Europe/Paris
      - Europe/Podgorica
      - Europe/Prague
      - Europe/Riga
      - Europe/Rome
      - Europe/San_Marino
      - Europe/Skopje
      - Europe/Sofia
      - Europe/Stockholm
      - Europe/Tallinn
      - Europe/Tirane
      - Europe/Vaduz
      - Europe/Vatican
      - Europe/Vienna
      - Europe/Vilnius
      - Europe/Warsaw
      - Europe/Zurich
      - Indian/Antananarivo
      - Indian/Chagos
      - Indian/Christmas
      - Indian/Cocos
      - Indian/Comoro
      - Indian/Kerguelen
      - Indian/Mahe
      - Indian/Maldives
      - Indian/Mauritius
      - Indian/Mayotte
      - Indian/Reunion
      - Pacific/Apia
      - Pacific/Auckland
      - Pacific/Bougainville
      - Pacific/Chatham
      - Pacific/Chuuk
      - Pacific/Easter
      - Pacific/Efate
      - Pacific/Enderbury
      - Pacific/Fakaofo
      - Pacific/Fiji
      - Pacific/Funafuti
      - Pacific/Galapagos
      - Pacific/Gambier
      - Pacific/Guadalcanal
      - Pacific/Guam
      - Pacific/Honolulu
      - Pacific/Kiritimati
      - Pacific/Kosrae
      - Pacific/Kwajalein
      - Pacific/Majuro
      - Pacific/Marquesas
      - Pacific/Midway
      - Pacific/Nauru
      - Pacific/Niue
      - Pacific/Norfolk
      - Pacific/Noumea
      - Pacific/Pago_Pago
      - Pacific/Palau
      - Pacific/Pitcairn
      - Pacific/Pohnpei
      - Pacific/Port_Moresby
      - Pacific/Rarotonga
      - Pacific/Saipan
      - Pacific/Tahiti
      - Pacific/Tarawa
      - Pacific/Tongatapu
      - Pacific/Wake
      - Pacific/Wallis
      - UTC
  DictionaryType: 
    Type: String
    Default: Postgres
    AllowedValues: 
      - Postgres
      - MySQL
      - MSSQL
  AuditType:
    Type: String
    Default: Postgres
    AllowedValues: 
      - Postgres
      - MySQL
      - MSSQL
      - AuroraPostgres
      - AuroraMySQL
  CloudWatchLogSyncEnabled:
    Type: String
    Default: 'ON'
    AllowedValues:
      - 'OFF'
      - 'ON'
    Description: Enabling DataSunrise logs integration into CloudWatch
  CloudWatchLogSyncInterval:
    Type: String
    Default: '5'
    Description: DataSunrise & CloudWatch logs synchronization interval (minutes)
  DeploymentName:
    Type: String
    Description: >-
      Name that will be used as the prefix to the resourses' names that will be
      created by the Cloud Formation script (only in lower case, not more than
      15 symbols and not less than 5 symbols)
    AllowedPattern: '[a-z][a-z0-9]*'
    MaxLength: '15'
    MinLength: '5'
  DSDistributionUrl:
    Type: String
    Description: '(Optional) Url of the DataSunrise distribution package. Make sure that this URL will be accessible from your VPC. You may also use the path to the DataSunrise build placed in your S3 bucket, however, make sure to modify the S3AccessPolicy section of this template. || Example: s3://bucketnmae/installername.run || Example: https://linktothebuild'
  DSLicenseType:
    Type: String
    Default: BYOL
    AllowedValues:
      - HourlyBilling
      - BYOL
    Description: >-
      Preferred licensing type. If you select BYOL licensing, you must enter
      valid license key into DSLicenseKey field.
  DSLicenseKey:
    Type: String
    Default: Do not change this field if you are using hourly billing
    Description: The DataSunrise license key.
  DBUser:
    Type: String
    NoEcho: 'true'
    Description: >-
      The database administrator account username. Must begin with a letter and
      contain only alphanumeric characters.
    Default: dsuser
    MinLength: '1'
    MaxLength: '16'
    AllowedPattern: '[a-zA-Z][a-zA-Z0-9]*'
    ConstraintDescription: must begin with a letter and contain only alphanumeric characters
  DBPassword:
    Type: String
    NoEcho: 'true'
    Description: The database administrator account password.
    MinLength: '8'
    MaxLength: '41'
  DSAdminPassword:
    Type: String
    NoEcho: 'true'
    Description: The password must contain at least 8 characters, lower and upper case, numbers and special characters.
    MinLength: '8'
    MaxLength: '41'
    AllowedPattern: ^.*(?=.{8,})(?=.*[a-zA-Z])(?=.*\d)(?=.*[\[\]|\\{}=_\/?<>,.:;~`"!@#$%^&*()+-]).*$
  DictionaryDBClass:
    Type: String
    Description: >-
      The database instance class that allocates the computational, network, and
      memory capacity required by planned workload of this database instance.
    Default: db.t3.medium
    AllowedValues:
      - db.t3.small
      - db.t3.medium
      - db.t3.large
      - db.t3.xlarge
      - db.t3.2xlarge
      - db.m5.large
      - db.m5.xlarge
      - db.m5.2xlarge
      - db.m5.4xlarge
      - db.m5.12xlarge
      - db.m5.24xlarge
      - db.r5.large
      - db.r5.xlarge
      - db.r5.2xlarge
      - db.r5.4xlarge
      - db.r5.12xlarge
      - db.r5.24xlarge
  DBDictName:
    Type: String
    Description: >-
      Name of the database to store DataSunrise configuration. Must begin with a
      letter and contain only alphanumeric characters.
    Default: dsdictionary
    MinLength: '1'
    MaxLength: '64'
    AllowedPattern: '[a-zA-Z][a-zA-Z0-9]*'
    ConstraintDescription: must begin with a letter and contain only alphanumeric characters
  MultiAzDictionary:
    AllowedValues:
      - 'true'
      - 'false'
    Default: 'true'
    Description: Dictionary RDS Multi-AZ
    Type: String
  DictionaryDBStorageSize:
    Type: Number
    Default: '20'
    Description: 'The size of the database (Gb), minimum restriction by AWS is 20GB'
    MinValue: '20'
    MaxValue: '1024'
    ConstraintDescription: must be between 5 and 1024Gb.
  AuditDBClass:
    Type: String
    Description: >-
      The database instance class that allocates the computational, network, and
      memory capacity required by planned workload of this database instance.
    Default: 4xlarge
    AllowedValues:
      - xlarge
      - 2xlarge
      - 4xlarge
      - 8xlarge
      - 12xlarge
      - 16xlarge
      - 24xlarge
  DBAuditName:
    Type: String
    Description: >-
      Name of the database to store DataSunrise audit journal. Must begin with a
      letter and contain only alphanumeric characters.
    Default: dsaudit
    MinLength: '1'
    MaxLength: '64'
    AllowedPattern: '[a-zA-Z][a-zA-Z0-9]*'
    ConstraintDescription: must begin with a letter and contain only alphanumeric characters
  AuditDBStorageSize:
    Type: Number
    Default: '200'
    Description: 'The size of the database (Gb), minimum restriction by AWS is 20GB'
    MinValue: '20'
    MaxValue: '1024'
    ConstraintDescription: must be between 20 and 1024Gb.
  MultiAzAudit:
    AllowedValues:
      - 'true'
      - 'false'
    Default: 'true'
    Description: Make Audit RDS Multi-AZ
    Type: String
  TDBType:
    Type: String
    Description: Type of target database.
    AllowedValues:
      - Aurora MySQL
      - Aurora PostgreSQL
      - Cassandra
      - DB2
      - DynamoDB
      - Greenplum
      - Hive
      - Impala
      - MariaDB
      - MongoDB
      - MSSQL
      - MySQL
      - Netezza
      - Oracle
      - PostgreSQL
      - Redshift
      - SAP HANA
      - Teradata
      - Vertica
    AllowedPattern: .+
  TDBHost:
    Type: String
    Description: >-
      The target database endpoint address. Please make sure that database is
      accessible from network, mentioned upper.
    AllowedPattern: .+
  TDBPort:
    Type: String
    Description: The target database endpoint port. It will be applied for proxy port too.
    AllowedPattern: .+
  TDBName:
    Type: String
    Description: The target database name.
    AllowedPattern: .+
  TDBLogin:
    Type: String
    Description: Login for target database user.
    AllowedPattern: .+
  TDBPassword:
    Type: String
    NoEcho: 'true'
    Description: Password for target database user.
    AllowedPattern: .+
  TDBSecurityGroup:
    Type: 'AWS::EC2::SecurityGroup::Id'
    Description: Security Group of the Database to be protected.
  TDBEncryption:
    Type: String
    Description: >-
      (Optional) Use Encryption when connecting to the database (supported only
      for Aurora MySQL, MySQL, MariaDB, Cassandra, DB2, DynamoDB, MongoDB, Oracle,
      SAP HANA)
    AllowedValues:
      - 'true'
      - 'false'
    Default: 'false'
  AWSCLIProxy:
    Type: String
    Description: >-
      (Optional) In some cases of using private networks it is necessary to set
      up proxy for AWS CLI (PutMetrics/S3). For example
      http://[username[:password]@]<proxy_host>:<proxy_port>
    AllowedPattern: '(https?:\/\/((\S*@)?([a-zA-Z0-9.-]+(:\d{1,5}){1})))?'
    ConstraintDescription: 'You need specify the connection in a similar format "http://[username[:password]@]<proxy_host>:<proxy_port>"'
  AlarmEmail:
    Type: String
    Description: >-
      (Optional) The email address that receives SNS notifications when
      DataSunrise service is down.
  BackupS3BucketName:
    Type: String
    Description: >-
      (Optional) Name of the S3 bucket for DataSunrise backups & logs. If empty,
      the backup uploading will not be configured.
  VMKeyPair:
    Type: 'AWS::EC2::KeyPair::KeyName'
    Description: Name of an existing EC2 VMKeyPair to enable SSH access to the instance
    ConstraintDescription: must be the name of an existing EC2 VMKeyPair.
    AllowedPattern: .+
  VMInstanceType:
    Type: String
    Description: >-
      The instance type that allocates the computational, network, and memory
      capacity required by planned workload of this instance.
    Default: m5.2xlarge
    AllowedValues:
      - t3.medium
      - t3.large
      - t3.xlarge
      - t3.2xlarge
      - m5.large
      - m5.xlarge
      - m5.2xlarge
      - m5.4xlarge
      - m5.12xlarge
      - m5.24xlarge
      - c5.large
      - c5.xlarge
      - c5.2xlarge
      - c5.4xlarge
      - c5.9xlarge
      - c5.18xlarge
      - f1.2xlarge
      - f1.16xlarge
      - g3.4xlarge
      - g3.8xlarge
      - g3.16xlarge
      - g2.2xlarge
      - g2.8xlarge
      - p2.xlarge
      - p2.8xlarge
      - p2.16xlarge
      - p3.2xlarge
      - p3.8xlarge
      - p3.16xlarge
      - r4.large
      - r4.xlarge
      - r4.2xlarge
      - r4.4xlarge
      - r4.8xlarge
      - r4.16xlarge
      - x1.16xlarge
      - x1e.xlarge
      - x1e.2xlarge
      - x1e.4xlarge
      - x1e.8xlarge
      - x1e.16xlarge
      - x1e.32xlarge
      - x1.32xlarge
      - d2.xlarge
      - d2.2xlarge
      - d2.4xlarge
      - d2.8xlarge
      - i2.xlarge
      - i2.2xlarge
      - i2.4xlarge
      - i2.8xlarge
      - h1.2xlarge
      - h1.4xlarge
      - h1.8xlarge
      - h1.16xlarge
      - i3.large
      - i3.xlarge
      - i3.2xlarge
      - i3.4xlarge
      - i3.8xlarge
      - i3.16xlarge
      - t3a.medium
      - t3a.large
      - t3a.xlarge
      - t3a.2xlarge
      - r5.large
      - r5.xlarge
      - r5.2xlarge
      - r5.4xlarge
      - r5.8xlarge
      - r5.12xlarge
      - r5.16xlarge
      - r5.24xlarge
      - r5.metal
      - r5d.large
      - r5d.xlarge
      - r5d.2xlarge
      - r5d.4xlarge
      - r5d.8xlarge
      - r5d.12xlarge
      - r5d.16xlarge
      - r5d.24xlarge
      - r5d.metal
      - r5a.large
      - r5a.xlarge
      - r5a.2xlarge
      - r5a.4xlarge
      - r5a.8xlarge
      - r5a.12xlarge
      - r5a.16xlarge
      - r5a.24xlarge
      - r5ad.large
      - r5ad.xlarge
      - r5ad.2xlarge
      - r5ad.4xlarge
      - r5ad.8xlarge
      - r5ad.12xlarge
      - r5ad.16xlarge
      - r5ad.24xlarge
  VPC:
    Description: Prefered VPC Id
    Type: 'AWS::EC2::VPC::Id'
    ConstraintDescription: must be the VPC Id of an existing Virtual Private Cloud.
    AllowedPattern: .+
  SubnetsASGLB:
    Type: 'List<AWS::EC2::Subnet::Id>'
    Description: >-
      Load Balancer and EC2 instances subnets. Must be a part of mentioned VPC.
    ConstraintDescription: must be the subnet Id of an existing subnet in mentioned VPC.
    AllowedPattern: .+
  AdminLocationCIDR:
    AllowedPattern: '(\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3})/(\d{1,2})'
    ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/x.
    Description: >-
      IP address range that can be used access port 22, for appliance
      configuration access to the EC2 instances.
    MaxLength: '18'
    MinLength: '9'
    Type: String
    Default: '0.0.0.0/0'
  UserLocationCIDR:
    AllowedPattern: '(\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3})/(\d{1,2})'
    ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/x.
    Description: >-
      IP address range that can be used access port 11000, for appliance
      configuration access to the DataSunrise console and database proxy.
    MaxLength: '18'
    MinLength: '9'
    Type: String
    Default: '0.0.0.0/0'
  EC2Count:
    Type: String
    Default: '2'
    AllowedPattern: '[0-9]+'
    Description: Count of EC2 DataSunrise Server to be launched.
  AHealthCheckType:
    Type: String
    Description: >-
      The service you want the health status from, Amazon EC2 or Elastic Load
      Balancer.
    Default: EC2
    AllowedValues:
      - EC2
      - ELB
  ELBScheme:
    Type: String
    Description: >-
      For load balancers attached to an Amazon VPC, this parameter can be used
      to specify the type of load balancer to use. Specify internal to create an
      internal load balancer with a DNS name that resolves to private IP
      addresses or internet-facing to create a load balancer with a publicly
      resolvable DNS name, which resolves to public IP addresses.
    AllowedValues:
      - internal
      - internet-facing
  BucketKeyARN:
    Type: String
    Description: >-
      (Optional) KMS Key ARN that was used for S3 bucket encryption. The key is
      needed for DSDistribution download possibility. In case the bucket is not
      encrypted, leave this field empty.
  SubnetsConfig:
    Type: 'List<AWS::EC2::Subnet::Id>'
    Description: >-
      Dictionary and Audit subnets. Must be a part of mentioned VPC. Please be sure
      that you select at least two subnets.
    ConstraintDescription: must be the subnet Id of an existing subnet in mentioned VPC.
    AllowedPattern: .+
Conditions:
  HasS3Name: !Not [!Equals ['', !Ref BackupS3BucketName]]
  HasNoAlarm: !Equals ['', !Ref AlarmEmail]
  HasAlarm: !Not [!Equals ['', !Ref AlarmEmail]]
  HasBucketKeyARN: !Not [!Equals ['', !Ref BucketKeyARN]]
  DictionaryPostgres: !Equals [ !Ref DictionaryType, 'Postgres']
  DictionaryMysql: !Equals [!Ref DictionaryType, 'MySQL']
  DictionaryMssql: !Equals [!Ref DictionaryType, 'MSSQL']
  AuditPostgres: !Equals [ !Ref AuditType, 'Postgres']
  AuditMysql: !Equals [!Ref AuditType, 'MySQL']
  AuditMssql: !Equals [!Ref AuditType, 'MSSQL']
  AuditAuroraPostgres: !Equals [ !Ref AuditType, 'AuroraPostgres']
  AuditAuroraMysql: !Equals [!Ref AuditType, 'AuroraMySQL']
  ParameterGroupPg: !Or [!Equals [!Ref DictionaryType, 'Postgres'],!Equals [ !Ref AuditType, 'Postgres']]
  ParameterGroupMy: !Or [!Equals [!Ref DictionaryType, 'MySQL'], !Equals [ !Ref AuditType, 'MySQL']]
  ParameterGroupMsDictionary: !Equals [!Ref DictionaryType, 'MSSQL']
  ParameterGroupMsAudit: !Equals [!Ref DictionaryType, 'MSSQL']
  isAuroraCluster: !Or [!Equals [!Ref AuditType, 'AuroraPostgres'],!Equals [ !Ref AuditType, 'AuroraMySQL']]
  isNotAuroraCluster: !Not [!Or [!Equals [!Ref AuditType, 'AuroraPostgres'],!Equals [ !Ref AuditType, 'AuroraMySQL']]]
  s3link: !Equals [!Select [0, !Split ['//', !Ref DSDistributionUrl]], 's3:']
  HasADJoin: !Not [!Equals ['', !Ref DirectoryServiceId]]
  HasADPasswd: !Not [!Equals ['', !Ref ADPassword]]
Metadata:
  'AWS::CloudFormation::Interface':
    ParameterGroups:
      - Label:
          default: Deployment name
        Parameters:
          - DeploymentName
      - Label:
          default: Virtual Machine Configuration
        Parameters:
          - TimeZone
          - VMKeyPair
          - VMInstanceType
      - Label:
          default: Network Configuration
        Parameters:
          - VPC
          - AdminLocationCIDR
          - UserLocationCIDR
      - Label:
          default: DataSunrise Configuration
        Parameters:
          - DSAdminPassword
          - DSDistributionUrl
          - BucketKeyARN
          - DSLicenseType
          - DSLicenseKey
          - BackupS3BucketName
          - AlarmEmail
      - Label:
          default: Dictionary & Audit Database Configuration
        Parameters:
          - DictionaryType
          - DictionaryDBClass
          - DictionaryDBStorageSize
          - DBDictName
          - MultiAzDictionary
          - AuditType
          - AuditDBClass
          - AuditDBStorageSize
          - DBAuditName
          - MultiAzAudit
          - DBUser
          - DBPassword
          - SubnetsConfig
      - Label:
          default: Target Database Configuration
        Parameters:
          - TDBType
          - TDBHost
          - TDBPort
          - TDBName
          - TDBLogin
          - TDBPassword
          - TDBSecurityGroup
          - TDBEncryption
      - Label:
          default: Auto Scaling Group Configuration
        Parameters:
          - EC2Count
          - AHealthCheckType
          - SubnetsASGLB
      - Label:
          default: LoadBalancer Configuration
        Parameters:
          - ELBScheme
      - Label:
          default: DataSunrise & CloudWatch Integration
        Parameters:
          - CloudWatchLogSyncEnabled
          - CloudWatchLogSyncInterval
      - Label:
          default: AWS DirectoryService Integration (optional)
        Parameters:
          - DirectoryServiceId
          - ADLogin
          - ADPassword
          - ADCIDR
      - Label:
          default: Proxy Options
        Parameters:
          - AWSCLIProxy
Resources:
  dsSecretAdminPassword:
    Type: 'AWS::SecretsManager::Secret'
    Properties:
      Name: !Join ['',[!Ref DeploymentName, '-secret-admin-password']]
      Description: DataSunrise Administrator Password
      SecretString: !Ref DSAdminPassword
  dsSecretTargetDBPassword:
    Type: 'AWS::SecretsManager::Secret'
    Properties:
      Name: !Join ['', [!Ref DeploymentName, '-secret-tdb-password']]
      Description: DataSunrise Target Database Password
      SecretString: !Ref TDBPassword
  dsSecretConfigDBPassword:
    Type: 'AWS::SecretsManager::Secret'
    Properties:
      Name: !Join ['', [!Ref DeploymentName, '-secret-config-password']]
      Description: DataSunrise Configuration Database Password
      SecretString: !Ref DBPassword
  dsSecretLicenseKey:
    Type: 'AWS::SecretsManager::Secret'
    Properties:
      Name: !Join ['', [!Ref DeploymentName, '-secret-license-key']]
      Description: DataSunrise License
      SecretString: !Ref DSLicenseKey
  dsSecretADPassword:
     Type: AWS::SecretsManager::Secret
     Condition: HasADPasswd
     Properties:
         Name: !Join ['', [!Ref DeploymentName, '-secret-ad-password']]
         Description: AD join password
         SecretString: !Ref ADPassword
  DSTopic:
    Type: 'AWS::SNS::Topic'
    Condition: HasAlarm
    Properties:
      TopicName: !Join ['', [!Ref DeploymentName, '-DataSunrise-service-down']]
  DSTopicSubscription:
    Type: 'AWS::SNS::Subscription'
    Condition: HasAlarm
    Properties:
      Endpoint: !Ref AlarmEmail
      Protocol: email
      TopicArn: !Ref DSTopic
  EC2SG:
    Type: 'AWS::EC2::SecurityGroup'
    Properties:
      VpcId: !Ref VPC
      GroupName: !Join ['', [!Ref DeploymentName, '-DataSunrise-EC2-SG']]
      GroupDescription: Enables SSH and access to DataSunrise console (port 11000)
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: '22'
          ToPort: '22'
          CidrIp: !Ref AdminLocationCIDR
        - IpProtocol: tcp
          FromPort: '11000'
          ToPort: '11000'
          CidrIp: !Ref UserLocationCIDR
        - IpProtocol: tcp
          FromPort: !Ref TDBPort
          ToPort: !Ref TDBPort
          CidrIp: !Ref UserLocationCIDR
      Tags:
        - Key: Name
          Value: !Join ['', [!Ref DeploymentName, '-DataSunrise-EC2-SG']]
  EC2SGIngressRules11010:
    Type: 'AWS::EC2::SecurityGroupIngress'
    DependsOn:
      - EC2SG
    Properties:
      GroupId: !GetAtt EC2SG.GroupId
      IpProtocol: tcp
      FromPort: '11000'
      ToPort: '11010'
      SourceSecurityGroupId: !GetAtt EC2SG.GroupId
  TDBSGIngressRule:
    Type: AWS::EC2::SecurityGroupIngress
    Properties:
      GroupId: !Ref TDBSecurityGroup
      IpProtocol: tcp 
      FromPort: !Ref TDBPort
      ToPort: !Ref TDBPort
      SourceSecurityGroupId: !GetAtt EC2SG.GroupId
  EC2SGIngressRules4AD53TCP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: tcp
          FromPort: 53
          ToPort: 53
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4AD53UDP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: udp
          FromPort: 53
          ToPort: 53
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4AD88TCP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: tcp
          FromPort: 88
          ToPort: 88
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4AD88UDP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: udp
          FromPort: 88
          ToPort: 88
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4AD123UDP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: udp
          FromPort: 123
          ToPort: 123
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4AD135TCP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: tcp
          FromPort: 135
          ToPort: 135
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4AD137UDP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: udp
          FromPort: 137
          ToPort: 138
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4AD139TCP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: tcp
          FromPort: 139
          ToPort: 139
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4AD389TCP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: tcp
          FromPort: 389
          ToPort: 389
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4AD389UDP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: udp
          FromPort: 389
          ToPort: 389
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4AD455TCP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: tcp
          FromPort: 455
          ToPort: 455
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4AD455UDP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: udp
          FromPort: 455
          ToPort: 455
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4AD464TCP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: tcp
          FromPort: 464
          ToPort: 464
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4AD464UDP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: udp
          FromPort: 464
          ToPort: 464
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4AD636TCP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: tcp
          FromPort: 636
          ToPort: 636
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4AD873TCP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: tcp
          FromPort: 873
          ToPort: 873
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4AD3268TCP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: tcp
          FromPort: 3268
          ToPort: 3269
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4ADRPCTCP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: tcp
          FromPort: 1024
          ToPort: 65535
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4ADRPCUDP:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: udp
          FromPort: 1024
          ToPort: 65535
          CidrIp: !Ref ADCIDR
  EC2SGIngressRules4ADICMPAll:
      Type: AWS::EC2::SecurityGroupIngress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: icmp
          FromPort: -1
          ToPort: -1
          CidrIp: !Ref ADCIDR
  EC2SGEgressRules4ADTCP:
      Type: AWS::EC2::SecurityGroupEgress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: tcp
          FromPort: 0
          ToPort: 65535
          CidrIp: !Ref ADCIDR
  EC2SGEgressRules4ADUDP:
      Type: AWS::EC2::SecurityGroupEgress
      Condition: HasADJoin
      DependsOn:
        - EC2SG
      Properties:
          GroupId: !GetAtt EC2SG.GroupId
          IpProtocol: udp
          FromPort: 0
          ToPort: 65535
          CidrIp: !Ref ADCIDR
  S3AccessPolicy:
    Type: 'AWS::IAM::ManagedPolicy'
    Condition: HasS3Name
    Properties:
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - 's3:HeadBucket'
              - 's3:GetObject*'
              - 's3:PutObject*'
              - 's3:List*'
            Resource:
              - !Join ['', ['arn:aws:s3:::', !Ref BackupS3BucketName,'/*']]
              - !Join ['', ['arn:aws:s3:::', !Ref BackupS3BucketName]]
  S3GetDistributionPolicy:
    Type: 'AWS::IAM::ManagedPolicy'
    Condition: s3link
    Properties:
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - 's3:GetObject*'
            Resource:
              - !Join ['',['arn:aws:s3:::', !Select [1, !Split ['//', !Ref DSDistributionUrl]]]]
  KMSAccessPolicy:
    Type: 'AWS::IAM::ManagedPolicy'
    Condition: HasBucketKeyARN
    Properties:
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Action:
              - 'kms:Decrypt'
              - 'kms:Encrypt'
              - 'kms:DescribeKey'
            Resource:
              - !Join ['', [!Ref BucketKeyARN]]
  DSVMRole:
    Type: 'AWS::IAM::Role'
    Properties:
      RoleName: !Join ['', [!Ref DeploymentName, '-DataSunrise-EC2-Role']]
      ManagedPolicyArns:
        - !If [HasS3Name, !Ref S3AccessPolicy, !Ref 'AWS::NoValue']
        - !If [HasBucketKeyARN, !Ref KMSAccessPolicy, !Ref 'AWS::NoValue']
        - !If [s3link, !Ref S3GetDistributionPolicy, !Ref 'AWS::NoValue']
        - !If [HasADJoin, 'arn:aws:iam::aws:policy/AmazonSSMManagedInstanceCore', !Ref 'AWS::NoValue']
        - !If [HasADJoin, 'arn:aws:iam::aws:policy/AmazonSSMDirectoryServiceAccess', !Ref 'AWS::NoValue']
      AssumeRolePolicyDocument:
        Version: 2012-10-17
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - ec2.amazonaws.com
            Action:
              - 'sts:AssumeRole'
      Path: /
      Policies:
        - PolicyName: !Join ['', [!Ref DeploymentName, '-DataSunrise-VM-Policy']]
          PolicyDocument:
            Version: 2012-10-17
            Statement:
              - Effect: Allow
                Action:
                  - 'ec2:*SecurityGroup*'
                Resource:
                  - !Join ['', ['arn:aws:ec2:', !Ref 'AWS::Region', ':', !Ref 'AWS::AccountId', ':security-group/', !GetAtt EC2SG.GroupId]]
              - Effect: Allow
                Action:
                  - 'autoscaling:SetDesiredCapacity'
                  - 'autoscaling:UpdateAutoScalingGroup'
                  - 'autoscaling:CompleteLifecycleAction'
                  - 'autoscaling:PutLifecycleHook'
                Resource:
                  - !Join ['', ['arn:aws:autoscaling:', !Ref 'AWS::Region', ':', !Ref 'AWS::AccountId', ':autoScalingGroup:*:autoScalingGroupName/', !Join ['', [!Ref DeploymentName, '-asg']]]]
              - Effect: Allow
                Action:
                  - 'ssm:UpdateInstanceInformation'
                  - 'sts:DecodeAuthorizationMessage'
                  - 'ec2:DescribeInstanceStatus'
                  - 'ec2:DescribeInstances'
                  - 'aws-marketplace:MeterUsage'
                  - 'autoscaling:DescribeScalingActivities'
                Resource: '*'
              - Effect: Allow
                Action:
                  - 'cloudwatch:DeleteAlarms'
                Resource:
                  - !Join [ '',[ 'arn:aws:cloudwatch:', !Ref 'AWS::Region', ':', !Ref 'AWS::AccountId', ':alarm:', !Ref DeploymentName, '*' ] ]
              - Effect: Allow
                Action:
                  - 'rds:DescribeDBInstances'
                Resource:
                  - !Join [ '',[ 'arn:aws:rds:', !Ref 'AWS::Region', ':', !Ref 'AWS::AccountId', ':db:', !If [ isNotAuroraCluster, !Ref DSAuditDB, !Ref DSAuditDBClusterNode ] ] ]
              - Effect: Allow
                Action:
                  - 'secretsmanager:DescribeSecret'
                  - 'secretsmanager:GetSecretValue'
                  - 'secretsmanager:PutSecretValue'
                  - 'secretsmanager:UpdateSecretVersionStage'
                Resource:
                  - !Ref dsSecretAdminPassword
                  - !Ref dsSecretTargetDBPassword
                  - !Ref dsSecretConfigDBPassword
                  - !Ref dsSecretLicenseKey
                  - !If [ HasADPasswd, !Ref dsSecretADPassword, !Ref dsSecretLicenseKey ]
              - Effect: Allow
                Action:
                  - 'secretsmanager:GetSecretValue'
                Resource:
                  - !Join [ '', [ 'arn:aws:secretsmanager:', !Ref 'AWS::Region', ':', !Ref 'AWS::AccountId', ':secret:db-password-*' ] ]
              - Effect: Allow
                Action:
                  - 'cloudwatch:PutMetricStream'
                  - 'cloudwatch:PutMetricAlarm'
                Resource:
                  - !Join [ '', [ 'arn:aws:cloudwatch:', !Ref 'AWS::Region', ':', !Ref 'AWS::AccountId', ':alarm:*' ] ]
                  - !Join [ '', [ 'arn:aws:cloudwatch:', !Ref 'AWS::Region', ':', !Ref 'AWS::AccountId', ':metric-stream/*' ] ]
              - Effect: Allow
                Action:
                  - 'cloudwatch:PutMetricData'
                  - 'cloudwatch:GetMetricStatistics'
                Resource: '*'
              - Effect: Allow
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:Put*'
                  - 'logs:DescribeLogStreams'
                Resource:
                  - !Join [ '', [ 'arn:aws:logs:', !Ref 'AWS::Region', ':', !Ref 'AWS::AccountId', ':log-group:*' ] ]
                  - !Join [ '', [ 'arn:aws:logs:', !Ref 'AWS::Region', ':', !Ref 'AWS::AccountId', ':log-group:*:log-stream:*' ] ]
              - Effect: Allow
                Action:
                  - 'events:PutEvents'
                  - 'events:PutRule'
                Resource:
                  - !Join [ '', [ 'arn:aws:events:', !Ref 'AWS::Region', ':', !Ref 'AWS::AccountId', ':event-bus/*' ] ]
                  - !Join [ '', [ 'arn:aws:events:', !Ref 'AWS::Region', ':', !Ref 'AWS::AccountId', ':rule/*' ] ]
              - Effect: Allow
                Action:
                  - 'cloudformation:DeleteStack'
                Resource:
                  - !Join [ '', [ 'arn:aws:cloudformation:', !Ref 'AWS::Region', ':', !Ref 'AWS::AccountId', ':stack/', !Ref 'AWS::StackName' ] ]
  DSNodeProfile:
    Type: 'AWS::IAM::InstanceProfile'
    Properties:
      Roles:
        - !Ref DSVMRole
      InstanceProfileName: !Join ['', [!Ref DeploymentName, '-DataSunrise-VM-Profile']]
  DSDBSubnetGrp:
    Type: 'AWS::RDS::DBSubnetGroup'
    Properties:
      DBSubnetGroupDescription: RDS database subnet group for DataSunrise configuration storage.
      DBSubnetGroupName: !Join ['', [!Ref DeploymentName, '-dbsubnetgrp']]
      SubnetIds: !Ref SubnetsConfig
  DSConfigSG:
    Type: 'AWS::EC2::SecurityGroup'
    DependsOn:
      - EC2SG
    Properties:
      VpcId: !Ref VPC
      GroupName: !Join ['', [!Ref DeploymentName, '-DataSunrise-Config-SG']]
      GroupDescription: Enables DataSunrise nodes access to dictionary/audit RDS
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort:  !If [DictionaryPostgres, !FindInMap [Consts, V1, pgPort], !If [ DictionaryMysql, !FindInMap [Consts, V1, myPort], !FindInMap [Consts, V1, msPort]]]
          ToPort: !If [DictionaryPostgres, !FindInMap [Consts, V1, pgPort], !If [ DictionaryMysql, !FindInMap [Consts, V1, myPort], !FindInMap [Consts, V1, msPort]]]
          SourceSecurityGroupId: !GetAtt EC2SG.GroupId
      Tags:
        - Key: Name
          Value: !Join ['', [!Ref DeploymentName, '-DataSunrise-EC2-Config-SG']]
  DSConfigSGIngressRuleAudit:
    Type: 'AWS::EC2::SecurityGroupIngress'
    DependsOn:
      - DSConfigSG
      - EC2SG
    Properties:
      GroupId: !GetAtt DSConfigSG.GroupId
      IpProtocol: tcp
      FromPort: !If [AuditPostgres, !FindInMap [Consts, V1, pgPort], !If [AuditMysql, !FindInMap [Consts, V1, myPort], !If [AuditMssql, !FindInMap [Consts, V1, msPort], !If [AuditAuroraPostgres, !FindInMap [Consts, V1, pgPort], !FindInMap [Consts, V1, myPort]]]]]
      ToPort: !If [AuditPostgres, !FindInMap [Consts, V1, pgPort], !If [AuditMysql, !FindInMap [Consts, V1, myPort], !If [AuditMssql, !FindInMap [Consts, V1, msPort], !If [AuditAuroraPostgres, !FindInMap [Consts, V1, pgPort], !FindInMap [Consts, V1, myPort]]]]]
      SourceSecurityGroupId: !GetAtt EC2SG.GroupId
  DSDictionaryDB:
    Type: 'AWS::RDS::DBInstance'
    DependsOn:
      - DSDBSubnetGrp
      - DSConfigSG
    Properties:
      DBInstanceIdentifier: !Join ['', [!Ref DeploymentName, '-dictionary']]
      Engine: !If [DictionaryPostgres, !FindInMap [Consts, V1, DictionaryEnginePg], !If [DictionaryMysql, !FindInMap [Consts, V1, DictionaryEngineMy], !FindInMap [Consts, V1, DictionaryEngineMs]]]
      Port: !If [DictionaryPostgres, !FindInMap [Consts, V1, pgPort], !If [DictionaryMysql, !FindInMap [Consts, V1, myPort], !FindInMap [Consts, V1, msPort]]]
      EngineVersion: !If [DictionaryPostgres, !FindInMap [Consts, V1, EngineVersionPg], !If [DictionaryMysql, !FindInMap [Consts, V1, EngineVersionMy], !FindInMap [Consts, V1, EngineVersionMs]]]
      DBInstanceClass: !Ref DictionaryDBClass
      DBName: !If [DictionaryMssql, !Ref 'AWS::NoValue', !Ref DBDictName]
      MultiAZ: !Ref MultiAzDictionary
      MasterUsername: !Ref DBUser
      MasterUserPassword: !Ref DBPassword
      AllocatedStorage: !Ref DictionaryDBStorageSize
      VPCSecurityGroups:
        - !Ref DSConfigSG
      DBSubnetGroupName: !Ref DSDBSubnetGrp
      DBParameterGroupName: !If [DictionaryPostgres, !Ref DSParameterGroupPostgres, !If [DictionaryMysql, !Ref DSParameterGroupMysql, !Ref DSParameterGroupMssqlDictionary]]
      StorageEncrypted: !If [DictionaryMssql, !Ref 'AWS::NoValue', 'True']
      StorageType: gp2
      LicenseModel: !If [DictionaryPostgres, !FindInMap [Consts, V1, PostgresLicenseModel], !If [DictionaryMysql, !FindInMap [Consts, V1, MysqlLicenseModel], !FindInMap [Consts, V1, MssqlLicenseModel]]]
      DeletionProtection: true
      PubliclyAccessible: false
    DeletionPolicy: Snapshot
    UpdateReplacePolicy: Snapshot
  DSAuditDB:
    Condition: isNotAuroraCluster
    Type: 'AWS::RDS::DBInstance'
    DependsOn:
      - DSDBSubnetGrp
      - DSConfigSG
    Properties:
      DBInstanceIdentifier: !Join ['', [!Ref DeploymentName, '-audit']]
      Engine: !If [AuditPostgres, !FindInMap [Consts, V1, AuditEnginePg], !If [AuditMysql, !FindInMap [Consts, V1, AuditEngineMy], !FindInMap [Consts, V1, AuditEngineMs]]]
      Port: !If [AuditPostgres, !FindInMap [Consts, V1, pgPort], !If [AuditMysql, !FindInMap [Consts, V1, myPort], !If [AuditMssql, !FindInMap [Consts, V1, msPort], !If [AuditAuroraPostgres, !FindInMap [Consts, V1, pgPort], !FindInMap [Consts, V1, myPort]]]]]
      EngineVersion: !If [AuditPostgres, !FindInMap [Consts, V1, EngineVersionPg], !If [AuditMysql, !FindInMap [Consts, V1, EngineVersionMy], !FindInMap [Consts, V1, EngineVersionMs]]]
      DBInstanceClass: !Join ['', ['db.m5.', !Ref AuditDBClass]]
      DBName: !If [AuditMssql, !Ref 'AWS::NoValue', !Ref DBAuditName]
      #MSSQL DOENST HAVE A NAME FOR DB SHOULD BE AWS::NOVALUE IN CASE ITS MSSQL
      MultiAZ: !Ref MultiAzAudit
      MasterUsername: !Ref DBUser
      MasterUserPassword: !Ref DBPassword
      AllocatedStorage: !Ref AuditDBStorageSize
      VPCSecurityGroups:
        - !Ref DSConfigSG
      DBSubnetGroupName: !Ref DSDBSubnetGrp
      DBParameterGroupName: !If [AuditPostgres, !Ref DSParameterGroupPostgres, !If [AuditMysql, !Ref DSParameterGroupMysql, !Ref DSParameterGroupMssqlAudit]]
      StorageEncrypted: 'True'
      StorageType: gp2
      MaxAllocatedStorage: !If [AuditMssql, 16384, 65536]
      LicenseModel: !If [AuditPostgres, !FindInMap [Consts, V1, PostgresLicenseModel], !If [AuditMysql, !FindInMap [Consts, V1, MysqlLicenseModel], !FindInMap [Consts, V1, MssqlLicenseModel]]]
      DeletionProtection: true
      PubliclyAccessible: false
    DeletionPolicy: Snapshot
    UpdateReplacePolicy: Snapshot
  DSAuditDBCluster:
    Condition: isAuroraCluster
    Type: AWS::RDS::DBCluster
    Properties:
      DatabaseName: !Ref DBAuditName
      Engine: !If [AuditAuroraPostgres, !FindInMap [Consts, V1, AuditAuroraEnginePg], !FindInMap [Consts, V1, AuditAuroraEngineMy]]
      EngineVersion: !If [AuditAuroraPostgres, !FindInMap [Consts, V1, AuditAuroraEngineVersionPg], !FindInMap [Consts, V1, AuditAuroraEngineVersionMy]]
      MasterUsername: !Ref DBUser
      MasterUserPassword: !Ref DBPassword
      DBSubnetGroupName: !Ref DSDBSubnetGrp
      VpcSecurityGroupIds:
      - Ref: DSConfigSG
      DBClusterParameterGroupName: !If [AuditAuroraPostgres, !Ref DSParameterGroupPostgresCluster, !Ref DSParameterGroupMysqlCluster]
      DBClusterIdentifier: !Join ['', [!Ref DeploymentName, '-dsauditCluster']]
      Port: !If [AuditAuroraPostgres, !FindInMap [Consts, V1, pgPort], !FindInMap [Consts, V1, myPort]]
      StorageEncrypted: 'True'
  DSAuditDBClusterNode:
    Condition: isAuroraCluster
    Type: 'AWS::RDS::DBInstance'
    DependsOn:
      - DSDBSubnetGrp
      - DSConfigSG
    Properties:
      DBClusterIdentifier: !Ref DSAuditDBCluster
      Engine: !If [AuditAuroraPostgres, !FindInMap [Consts, V1, AuditAuroraEnginePg], !FindInMap [Consts, V1, AuditAuroraEngineMy]]
      DBInstanceClass: !Join ['', ['db.r5.', !Ref AuditDBClass]]
      DBSubnetGroupName: !Ref DSDBSubnetGrp
      DBInstanceIdentifier: !Join ['', [!Ref DeploymentName, '-dsauditnode']]
      PubliclyAccessible: false
  DSParameterGroupPostgres:
    Condition: ParameterGroupPg
    Type: AWS::RDS::DBParameterGroup
    Properties:
      Parameters:
        rds.force_ssl: '1'
      Description: DSParameterGroup
      Family: !FindInMap [Consts, V1, ParameterGroupFamilyPg]
  DSParameterGroupMysql:
    Condition: ParameterGroupMy
    Type: AWS::RDS::DBParameterGroup
    Properties:
      Parameters:
        character_set_server: utf8mb4
        collation_server: utf8mb4_bin
        character_set_database: utf8mb4
        log_bin_trust_function_creators: '1'
      Description: DSParameterGroup
      Family: !FindInMap [Consts, V1, ParameterGroupFamilyMy]
  DSParameterGroupMssqlAudit:
    Condition: AuditMssql
    Type: AWS::RDS::DBParameterGroup
    Properties:
      Parameters:
        rds.force_ssl: '1'
      Description: DSParameterGroup
      Family: !FindInMap [Consts, V1, AuditParameterGroupFamilyMs]
  DSParameterGroupMssqlDictionary:
    Condition: DictionaryMssql
    Type: AWS::RDS::DBParameterGroup
    Properties:
      Parameters:
        rds.force_ssl: '1'
      Description: DSParameterGroup
      Family: !FindInMap [Consts, V1, DictionaryParameterGroupFamilyMs]
  DSParameterGroupPostgresCluster:
    Condition: AuditAuroraPostgres
    Type: AWS::RDS::DBClusterParameterGroup
    Properties:
      Parameters:
        rds.force_ssl: '1'
      Description: DSParameterGroup
      Family: !FindInMap [Consts, V1, ParameterGroupFamilyPgCluster]
  DSParameterGroupMysqlCluster:
    Condition: AuditAuroraMysql
    Type: AWS::RDS::DBClusterParameterGroup
    Properties:
      Parameters:
        character_set_server: utf8mb4
        collation_server: utf8mb4_bin
        character_set_database: utf8mb4
        log_bin_trust_function_creators: '1'
      Description: DSParameterGroup
      Family: !FindInMap [Consts, V1, ParameterGroupFamilyMyCluster]
  DSLoadBalancer:
    Type: 'AWS::ElasticLoadBalancingV2::LoadBalancer'
    DependsOn:
      - DSWebUITargetGroup
      - DSTDBTargetGroup
    Properties:
      Type: network
      IpAddressType: ipv4
      Scheme: !Ref ELBScheme
      Name: !Join ['', [!Ref DeploymentName, '-lb']]
      Subnets: !Ref SubnetsASGLB
  DSWebUITargetGroup:
    Type: 'AWS::ElasticLoadBalancingV2::TargetGroup'
    Properties:
      Name: !Join ['', [!Ref DeploymentName, '-dswebuitg']]
      Protocol: TCP
      Port: '11000'
      VpcId: !Ref VPC
  DSTDBTargetGroup:
    Type: 'AWS::ElasticLoadBalancingV2::TargetGroup'
    Properties:
      Name: !Join ['', [!Ref DeploymentName, '-dstdbtg']]
      Protocol: TCP
      Port: !Ref TDBPort
      VpcId: !Ref VPC
      HealthCheckPath: !Join ['', ['/healthcheck/instance?inst_name=DBInstance-', !Ref DeploymentName]]
      HealthCheckPort: '11000'
      HealthCheckProtocol: HTTPS
  DSWebUIListener:
    Type: 'AWS::ElasticLoadBalancingV2::Listener'
    DependsOn:
      - DSLoadBalancer
    Properties:
      DefaultActions:
        - Type: forward
          TargetGroupArn: !Ref DSWebUITargetGroup
      LoadBalancerArn: !Ref DSLoadBalancer
      Port: '11000'
      Protocol: TCP
  DSTDBListener:
    Type: 'AWS::ElasticLoadBalancingV2::Listener'
    DependsOn:
      - DSLoadBalancer
    Properties:
      DefaultActions:
        - Type: forward
          TargetGroupArn: !Ref DSTDBTargetGroup
      LoadBalancerArn: !Ref DSLoadBalancer
      Port: !Ref TDBPort
      Protocol: TCP
  DSLaunchConf:
    Type: 'AWS::AutoScaling::LaunchConfiguration'
    DependsOn:
      - EC2SG
      - DSDictionaryDB
      - DSLoadBalancer
    Metadata:
      'AWS::CloudFormation::Init':
        configSets:
          AWSLinux1:
            - awscommon
            - common
        awscommon:
          files:
            /opt/cooked/cf-params.sh:
              content: !Sub 
              - |
                #!/bin/bash
                logTimestamp() {
                    local CURR_TS=`date "+%T.%6N"`
                    echo -ne "$CURR_TS "
                }
                logSeparator() {
                    logTimestamp
                    echo -ne "# -------------------------------------------------------------------------------\n"
                }
                log() {
                    logTimestamp
                    echo -ne "$INST_CAPT: $@\n"
                }
                logBeginAct() {
                    logSeparator
                    log $@
                }
                logEndAct() {
                    log $@
                    logSeparator
                }
                TOKEN=`curl -s -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 21600"`
                INST_ID=`curl -s http://169.254.169.254/latest/meta-data/instance-id -H "X-aws-ec2-metadata-token: $TOKEN"`
                CLOUD_INIT_LOG=/var/log/cloud-init-output.log

                DSDISTURL="${DSDistributionUrl}"
                DSLICTYPE=${DSLicenseType}
                CFSTACKNAME=${AWS::StackName}
                CFDEPLOYMENTNAME=${DeploymentName}
                EC2REGION=${AWS::Region}
                DSCLOUDDIR=${DSCloudRoot}

                DSROOT=${DSRoot}
                
                AWS_DS_ID=${AWSADId}
                AWS_DS_LOGIN=${AWSADLogin}
                
                AWS_AMI_PCODE=${AMIProductCode}
                AWS_CAR_PCODE=${CARProductCode}
               
                InitialAMinSize=${EC2Count}
                ASG_NAME='${DeploymentName}-asg'
                BackupS3BucketName=${BackupS3BucketName}
                AWSCLIProxy=${AWSCLIProxy}
                DSSecGroupId=${EC2SG.GroupId}
                AlarmSNSTopic=${AlarmSNSTopic}
                ELBProxyEndpoint=${DSLoadBalancer.DNSName}
                AlarmNamePrefix="ServiceAliveAlarm"
                AlarmName="$AlarmNamePrefix-$INST_ID"

                DS_SERVER=ds-$INST_ID
                DS_HOSTNAME=`curl -s http://169.254.169.254/latest/meta-data/hostname -H "X-aws-ec2-metadata-token: $TOKEN"`
                DS_HOST_PRIVIP=`curl -s http://169.254.169.254/latest/meta-data/local-ipv4 -H "X-aws-ec2-metadata-token: $TOKEN"`
                AF_HOME=$DSROOT
                AF_CONFIG=$AF_HOME

                TRG_INSTNAME='DBInstance-${DeploymentName}'
                TRG_DBTYPE='${TDBType}'
                TRG_DBHOST=${TDBHost}
                TRG_DBPORT=${TDBPort}
                TRG_DBNAME="${TDBName}"
                TRG_DBUSER="${TDBLogin}"
                TRG_ENCRYPTION="${TDBEncryption}"

                HA_DBTYPE=${DictionaryInternalParameter}
                HA_DBHOST=${DSDictionaryDB.Endpoint.Address}
                HA_DBPORT=${DSDictionaryDB.Endpoint.Port}
                HA_DBNAME=${DBDictName}
                HA_DBUSER=${DBUser}

                # 0 - Sqlite, 1 - PgSQL, 2 - MySQL, 3 - Redshift, 4 - Aurora
                HA_AUTYPE=${AuditInternalParameter}
                HA_AUHOST=${DSAuditDBHost}
                HA_AUPORT=${DSAuditDBPort}
                HA_AUNAME=${DBAuditName}
                HA_AUUSER=${DBUser}
                
                #used only for waiting for cluster node to be up
                HA_AUHOST_CLUSTER_NODE=${DSAuditDBHostClusterNode}
                
                CWLOGUPLOAD_ENABLED=${CloudWatchLogSyncEnabled}
                CWLOGUPLOAD_INTERVAL=${CloudWatchLogSyncInterval}

                INST_CAPT="[DS $INST_ID]"
                SSHADMINCIDR=${AdminLocationCIDR}
              - {
                  DSCloudRoot: !FindInMap [Consts, V1, DSCloudRoot],
                  DSRoot: !FindInMap [Consts, V1, DSRoot],
                  AMIProductCode: !FindInMap [Consts, V1, AMIProductCode],
                  CARProductCode: !FindInMap [Consts, V1, CARProductCode],
                  DictionaryInternalParameter: !If [DictionaryPostgres, !FindInMap [Consts, V1, DictionaryInternalParameterPg], !If [DictionaryMysql, !FindInMap [Consts, V1, DictionaryInternalParameterMy], !FindInMap [Consts, V1, DictionaryInternalParameterMs]]],
                  AuditInternalParameter: !If [AuditPostgres, !FindInMap [Consts, V1, AuditInternalParameterPg], !If [AuditMysql, !FindInMap [Consts, V1, AuditInternalParameterMy], !If [AuditMssql, !FindInMap [Consts, V1, AuditInternalParameterMs], !If [AuditAuroraPostgres, !FindInMap [Consts, V1, AuditInternalParameterPg], !FindInMap [Consts, V1, AuditInternalParameterMy]]]]],
                  AlarmSNSTopic: !If [HasAlarm, DSTopic, ''],
                  DSAuditDBHost: !If [isAuroraCluster, !GetAtt DSAuditDBCluster.Endpoint.Address, !GetAtt DSAuditDB.Endpoint.Address],
                  DSAuditDBPort: !If [AuditPostgres, !FindInMap [Consts, V1, pgPort], !If [AuditMysql, !FindInMap [Consts, V1, myPort], !If [AuditMssql, !FindInMap [Consts, V1, msPort], !If [AuditAuroraPostgres, !FindInMap [Consts, V1, pgPort], !FindInMap [Consts, V1, myPort]]]]],
                  DSAuditDBHostClusterNode: !If [isAuroraCluster, !GetAtt DSAuditDBClusterNode.Endpoint.Address, !GetAtt DSAuditDB.Endpoint.Address],
                  AWSADId: !Ref DirectoryServiceId,
                  AWSADLogin: !Ref ADLogin
                }
              mode: '000755'
              owner: ec2-user
              group: ec2-user
            /opt/cooked/ad-setup.sh:
                content: !Sub |
                    #!/bin/bash
                    adGetInfo() {
                        logBeginAct "Getting AD info for $AWS_DS_ID..."
                        AWS_DS_DESC=`aws ds describe-directories --directory-id $AWS_DS_ID`
                        if [ -z "$AWS_DS_DESC" ]; then
                            echo "Error - aws ds describe-directories FAILED - $?"
                        else
                            AWS_DS_NAME=`echo $AWS_DS_DESC | python -c "import sys, json; print json.load(sys.stdin)['DirectoryDescriptions'][0]['Name']"`
                            AWS_DS_SNAME=`echo $AWS_DS_DESC | python -c "import sys, json; print json.load(sys.stdin)['DirectoryDescriptions'][0]['ShortName']"`
                            AWS_DS_DNS1=`echo $AWS_DS_DESC | python -c "import sys, json; print json.load(sys.stdin)['DirectoryDescriptions'][0]['DnsIpAddrs'][0]"`
                            AWS_DS_DNS2=`echo $AWS_DS_DESC | python -c "import sys, json; print json.load(sys.stdin)['DirectoryDescriptions'][0]['DnsIpAddrs'][1]"`
                            log "AWS_DS_ID    - $AWS_DS_ID"
                            log "AWS_DS_NAME  - $AWS_DS_NAME"
                            log "AWS_DS_SNAME - $AWS_DS_SNAME"
                            log "AWS_DS_DNS1  - $AWS_DS_DNS1"
                            log "AWS_DS_DNS2  - $AWS_DS_DNS2"
                        fi
                        logEndAct "Getting AD info for $AWS_DS_ID - DONE"
                    }
                    adSetupKerberos() {
                        local KRB5_CONF=/etc/krb5.conf
                        local KRB5_CONF_BAK=/etc/krb5.conf.bak
                        logBeginAct "Setup kerberos configuration..."
                        cat > /tmp/krb5.conf <<EOF
                    [libdefaults]
                        default_realm       = $AWS_DS_NAME
                        dns_lookup_realm    = false
                        ticket_lifetime     = 24h
                        renew_lifetime      = 7d
                        forwardable         = true
                        rdns                = false
                        default_ccache_name = KEYRING:persistent:%{uid}
                    EOF
                        mv -f $KRB5_CONF $KRB5_CONF_BAK
                        mv /tmp/krb5.conf $KRB5_CONF
                        cat $KRB5_CONF
                        logEndAct "$KRB5_CONF"
                    }
                    adAddDNSToHosts() {
                        local HOSTS_CONF=/etc/hosts
                        echo $AWS_DS_DNS1 $AWS_DS_NAME $AWS_DS_SNAME | tee -a $HOSTS_CONF
                        logBeginAct "Setup dns..."
                        cat $HOSTS_CONF
                        logEndAct "$HOSTS_CONF"
                    }
                    adSetupResolver() {
                        local RESOLV_CONF=/etc/resolv.conf
                        local RESOLV_CONF_BAK=/etc/resolv.conf.bak
                        logBeginAct "Setup resolver..."
                        cat > /tmp/resolv.conf <<EOF
                    domain $AWS_DS_NAME
                    search $AWS_DS_SNAME
                    EOF
                        mv -f $RESOLV_CONF $RESOLV_CONF_BAK
                        mv /tmp/resolv.conf $RESOLV_CONF
                        if [ ! -z "$AWS_DS_DNS1" ]; then
                            echo -ne "nameserver $AWS_DS_DNS1\n" | tee -a $RESOLV_CONF
                        fi
                        if [ ! -z "$AWS_DS_DNS2" ]; then
                            echo -ne "nameserver $AWS_DS_DNS2\n" | tee -a $RESOLV_CONF
                        fi
                        cat $RESOLV_CONF
                        service network restart
                        logEndAct "$RESOLV_CONF"
                    }
                    adJoin() {
                        local AWS_DS_PASSWD=`aws --region $EC2REGION secretsmanager get-secret-value --secret-id $CFDEPLOYMENTNAME-secret-ad-password --query SecretString --output text`
                        logBeginAct "Attempting to join to AD..."
                        bash -c "echo $AWS_DS_PASSWD | realm join --verbose -U $AWS_DS_LOGIN $AWS_DS_NAME"
                        logEndAct "Joint to AD $?"
                    }
                mode: '000755'
                owner: ec2-user
                group: ec2-user
            /opt/cooked/vm-creds.sh:
              content: !Sub |
                #!/bin/bash
                TOKEN=`curl -s -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 21600"`
                INSTID=`curl -s http://169.254.169.254/latest/meta-data/instance-id -H "X-aws-ec2-metadata-token: $TOKEN"`
                IAM_ROLE=`curl -s http://169.254.169.254/latest/meta-data/iam/security-credentials/ -H "X-aws-ec2-metadata-token: $TOKEN"`
                if [ -z "$IAM_ROLE" ]; then
                    echo "$INSTID: Security credentials for this instance is not found!"
                else
                    IAM_NOT_FOUND=`echo "$IAM_ROLE" | grep -i "not found"`
                    if [ -z "$IAM_NOT_FOUND" ]; then
                        IAM_CREDS=`curl -s "http://169.254.169.254/latest/meta-data/iam/security-credentials/$IAM_ROLE" -H "X-aws-ec2-metadata-token: $TOKEN"`
                        export AWS_ACCESS_KEY_ID=`echo $IAM_CREDS | python -c "import sys, json; print json.load(sys.stdin)['AccessKeyId']"`
                        export AWS_SECRET_ACCESS_KEY=`echo $IAM_CREDS | python -c "import sys, json; print json.load(sys.stdin)['SecretAccessKey']"`
                        export AWS_SESSION_TOKEN=`echo $IAM_CREDS | python -c "import sys, json; print json.load(sys.stdin)['Token']"`
                        export AWS_SECURITY_TOKEN=$AWS_SESSION_TOKEN
                        EC2_AVAIL_ZONE=`curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone -H "X-aws-ec2-metadata-token: $TOKEN"`
                        EC2_REGION="`echo "$EC2_AVAIL_ZONE" | sed -e 's:\([0-9][0-9]*\)[a-z]*$:\1:'`"
                        aws configure set aws_access_key_id $AWS_ACCESS_KEY_ID
                        aws configure set aws_secret_access_key $AWS_SECRET_ACCESS_KEY
                        aws configure set default.region $EC2_REGION
                        echo "$INSTID: Using $IAM_ROLE credentials."
                    else
                        echo "$INSTID: IAM role did not attached to this instance!"
                    fi
                fi
              mode: '000755'
              owner: ec2-user
              group: ec2-user
            /opt/cooked/aws-ds-setup.sh:
              content: !Sub |
                #!/bin/bash
                uploadSetupLogs() {
                    if [ ! -z "$BackupS3BucketName" ]; then
                        aws s3 cp $CLOUD_INIT_LOG s3://$BackupS3BucketName/Deploying/$INST_ID/
                    fi
                }
                uploadAllSetupLogs() {
                    uploadSetupLogs
                    if [ ! -z "$BackupS3BucketName" ]; then
                        aws s3 sync $DSROOT/logs s3://$BackupS3BucketName/Deploying/$INST_ID/
                    fi
                }
                setupCWLogUploading() {
                    if [ "$CWLOGUPLOAD_ENABLED" == "ON" ]; then
                        logBeginAct "Setup CloudWatch Logs synchronization..."
                        echo -ne "*/$CWLOGUPLOAD_INTERVAL * * * * root $DSCLOUDDIR/push-cwlogs-conf.sh\n" | tee --append /etc/crontab
                        rm -f /etc/awslogs/awslogs.conf
                        rm -fr /root/.aws
                        systemctl stop awslogsd.service
                        sed -i "s/.*region =.*/region = $EC2REGION/" /etc/awslogs/awscli.conf
                        logEndAct "Setup CloudWatch Logs synchronization DONE"
                    fi
                }
                stsDecodeMessage() {
                    aws sts decode-authorization-message --encoded-message "$1"
                }
                stsDecodeMessageJSon() {
                    local jtmp=`stsDecodeMessage $1 | python -c "import sys, json; jnp=json.load(sys.stdin)['DecodedMessage']; print jnp"`
                    echo "$jtmp" | python -c "import sys, json; jnp=json.load(sys.stdin); print json.dumps(jnp, indent=4)"
                }
                setupCloudWatch() {
                    if [ ! -z "$AlarmSNSTopic" ]; then
                        logBeginAct "Setup service monitoring and alarm..."
                        aws cloudwatch put-metric-alarm \
                            --alarm-name "$AlarmName" \
                            --alarm-description "DataSunrise service alive alarm" \
                            --metric-name "ServiceAlive" \
                            --namespace "DataSunrise" \
                            --statistic Average \
                            --period 60 \
                            --threshold 1 \
                            --comparison-operator LessThanThreshold \
                            --dimensions "Name=InstanceId,Value=$INST_ID" \
                            --evaluation-periods 3 \
                            --alarm-actions "$AlarmSNSTopic"
                        RETVAL=$?
                        if [ $RETVAL -eq 0 ]; then
                            echo -ne "*/1 * * * * root $DSCLOUDDIR/service-mon.sh\n" | tee --append /etc/crontab
                        fi
                        logEndAct "Setup service monitoring and alarm result - $RETVAL"
                    fi
                }
              mode: '000755'
              owner: ec2-user
              group: ec2-user
            /opt/cooked/backup-upload.sh:
              content: !Sub |
                #!/bin/bash
                DSCLOUDDIR=/opt/ds-cloud
                PROXY_CONF=
                if [ ! -z "$PROXY_CONF" ]; then
                    export HTTP_PROXY="$PROXY_CONF"
                    export HTTPS_PROXY="$PROXY_CONF"
                fi
                BACKUP_TMPDIR=/tmp/ds-backups
                BACKUP_BUCKET=$1
                if [ -z "$BACKUP_BUCKET" ]; then
                    exit 1
                fi
                source $DSCLOUDDIR/vm-creds.sh
                TOKEN=`curl -s -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 21600"`
                INST_ID=`curl -s http://169.254.169.254/latest/meta-data/instance-id -H "X-aws-ec2-metadata-token: $TOKEN"`
                uploadBackup() {
                    echo -ne "Upload '$1'...\n"
                    aws s3 $S3_CMDARGS cp $1 $BACKUP_BUCKET/Backup/$INST_ID/
                    uplrv=$?
                    if [ $uplrv -eq 0 ]; then
                        rm -f $1
                    fi
                }
                goThrough() {
                    for fent in $1/*
                    do
                        if [ -d "${!fent}" ]; then
                            goThrough $fent
                        else
                            if [ -f "${!fent}" ]; then
                                uploadBackup $fent
                            fi
                        fi
                    done
                }
                goThrough $BACKUP_TMPDIR
              mode: '000755'
              owner: ec2-user
              group: ec2-user
            /opt/cooked/service-mon.sh:
              content: !Sub |
                #!/bin/bash
                DSCLOUDDIR=/opt/ds-cloud
                PROXY_CONF=
                if [ ! -z "$PROXY_CONF" ]; then
                    export HTTP_PROXY="$PROXY_CONF"
                    export HTTPS_PROXY="$PROXY_CONF"
                fi
                TOKEN=`curl -s -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 21600"`
                INST_ID=`curl -s http://169.254.169.254/latest/meta-data/instance-id -H "X-aws-ec2-metadata-token: $TOKEN"`
                sendAliveMetric() {
                    aws cloudwatch put-metric-data --metric-name "ServiceAlive" --namespace "DataSunrise" --value $1 --dimensions InstanceId=$INST_ID
                }
                source $DSCLOUDDIR/vm-creds.sh
                STEXT=`service datasunrise status 2> /dev/null`
                SSTATUS=$?
                if [ $SSTATUS -ne 0 ]; then
                    echo $STEXT
                    sendAliveMetric 0
                    exit $SSTATUS
                fi
                sendAliveMetric 1
              mode: '000755'
              owner: ec2-user
              group: ec2-user
            /opt/cooked/push-cwlogs-conf.sh:
              content: !Sub |
                #!/bin/bash
                DSCLOUDDIR=/opt/ds-cloud
                source $DSCLOUDDIR/cf-params.sh
                LOGD=$DSROOT/logs
                CONF=/tmp/awslogs.conf
                MAINCONF=/opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent-config.json
                function process_entry {
                    local LOG=$1
                    local LOGNAME=$(basename "${!LOG%.*}")
                    local ENT="{
                \"file_path\": \"$LOG\", 
                \"log_stream_name\": \"$LOGNAME\",
                \"log_group_name\": \"$CFDEPLOYMENTNAME/{instance_id}\"},"
                    echo -ne ">> $LOG\n"
                    echo -ne "$ENT\n" >> $CONF
                }
                function make_list {
                    local LOGS=(`ls -t $LOGD/$1*`)
                    for log in "${!LOGS[@]}"
                    do
                        process_entry $log
                    done
                }
                agentconf="\n 
                { \n 
                \"agent\": { \n 
                \"run_as_user\": \"root\" 
                }, \n 
                \"logs\": { 
                \"force_flush_interval\": 5,
                \"logs_collected\": { 
                \"files\": { 
                \"collect_list\": [ 
                " 
                echo -ne "$agentconf" >> $CONF
                echo -ne >> $CONF
                echo -ne >> $CONF
                make_list BackendLog
                echo -ne >> $CONF
                echo -ne >> $CONF
                make_list CoreLog
                echo -ne >>$CONF
                make_list WebLog
                echo -ne >> $CONF
                sed -i '$ s/.$//' /tmp/awslogs.conf
                echo -ne >> $CONF
                OUTPUT="
                ] \n } \n } \n } \n } \n 
                "  
                echo -ne "$OUTPUT" >> $CONF 
                mv -f $CONF $MAINCONF
                chmod 755 $LOGD
                service awslogsd stop
                /opt/aws/amazon-cloudwatch-agent/bin/amazon-cloudwatch-agent-ctl -a fetch-config -m ec2 -c file:/opt/aws/amazon-cloudwatch-agent/etc/amazon-cloudwatch-agent-config.json -s
              mode: '000755'
              owner: ec2-user
              group: ec2-user
        common:
          files:
            /opt/cooked/backup-prepare.sh:
              content: !Sub |
                #!/bin/bash
                DTF=`date '+%Y-%m-%d-%H-%M-%S'`
                BACKUP_TMPDIR=/tmp/ds-backups
                BACKUP_INP=$1
                BACKUP_NAME_PREFIX=$2
                if [ -z "$BACKUP_INP" ]; then
                    exit 1
                fi
                if [ -z "$BACKUP_NAME_PREFIX" ]; then
                    BACKUP_NAME_PREFIX=${!BACKUP_INP##*/}
                    if [ -z "$BACKUP_NAME_PREFIX" ]; then
                        BACKUP_NAME_PREFIX=Generic
                    fi
                fi
                BACKUP_NAME="${!BACKUP_NAME_PREFIX}-backup-$DTF"
                BACKUP_GZ=${!BACKUP_NAME}.tar.gz
                mkdir -p $BACKUP_TMPDIR
                tar czfP $BACKUP_TMPDIR/$BACKUP_GZ $BACKUP_INP
              mode: '000755'
              owner: ec2-user
              group: ec2-user
            /opt/cooked/ds-manip.sh:
              content: !Sub |
                #!/bin/bash
                  makeItMineParam() {
                      chown -R datasunrise:datasunrise "$1"
                  }
                  makeItMine() {
                      chown -R datasunrise:datasunrise !(PortBinder|AppFirewallCore_Sniffer)
                  }
                  cleanLogs() {
                      logBeginAct "Clean DS logs..."
                      rm -f $DSROOT/logs/Backend*
                      rm -f $DSROOT/logs/CoreLog*
                      rm -f $DSROOT/logs/WebLog*
                      logEndAct "Clean DS logs done - $?"
                  }
                  cleanSQLite() {
                      logBeginAct "Clean DS SQLite context..."
                      rm -f $DSROOT/audit.db*
                      rm -f $DSROOT/event.db*
                      rm -f $DSROOT/dictionary.db*
                      rm -f $DSROOT/local_settings.db*
                      rm -f $DSROOT/lock.db*
                      logEndAct "Clean DS SQLite context done - $?"
                  }
                  loginToDS() {
                      $DSROOT/cmdline/executecommand.sh connect -host 127.0.0.1 -login "$1" -password "$2"
                      RETVAL=$?
                  }
                  logoutDS() {
                      $DSROOT/cmdline/executecommand.sh disConnect -f
                      RETVAL=$?
                  }
                  loginAsAdmin() {
                      loginToDS admin "$DSAdminPassword"
                  }
              mode: '000755'
              owner: ec2-user
              group: ec2-user
            /opt/cooked/pre-setup.sh:
              content: !Sub
              - |
                #!/bin/bash
                installProduct() {
                    RETVAL=0
                    logBeginAct "Install DataSunrise..."
                    DS_INSTALLER=installer.run
                    if [ -z "$DSDISTURL" ]; then
                        log " Distribution URL is empty. Using stock installer."
                        ls -la
                    else
                        DS_INSTALLER=DSCustomBuild.run
                        if [[ "${!DSDISTURL:0:2}" == "S3" || "${!DSDISTURL:0:2}" == "s3" ]]; then
                            aws s3 cp "$DSDISTURL" $DS_INSTALLER --only-show-errors
                        else
                            wget "$DSDISTURL" -O $DS_INSTALLER -q
                        fi
                        if [[ "$?" != "0" ]]; then
                            log " Download was not successful, please check that URL is correct and available for downloading or S3AccessPolicy allows access to the bucket with the distribution file."
                            log " Installation will be interrupted."
                            RETVAL=2
                            return $RETVAL
                        fi
                    fi
                    if [ -z "$DS_INSTALLER" ]; then
                        logEndAct "DataSunrise binary not found!"
                        RETVAL=2
                        return $RETVAL
                    fi
                    chmod +x $DS_INSTALLER
                    log "Using binary: '$DS_INSTALLER'"
                    local DS_INSTALLER_CMD="./$DS_INSTALLER --target tmp install -f --no-password --no-start"
                    $DS_INSTALLER_CMD
                    RETVAL=$?
                    log "Result of '$DS_INSTALLER_CMD' is $RETVAL"
                    if [ "$RETVAL" != "0" ]; then
                        return $RETVAL
                    fi
                    log "Remove: '$DS_INSTALLER'"
                    rm -f $DS_INSTALLER
                    local DSCLOUDDIR=${DSCloudRoot}
                    log "Configuring SELinux support"
                    make -f /usr/share/selinux/devel/Makefile
                    semodule -i $DSCLOUDDIR/datasunrise.pp
                    #sed -i 's/SELINUX=permissive/SELINUX=enforcing/g' /etc/selinux/config
                    ######################################################
                    sed -i 's/SELINUX=enforcing/SELINUX=permissive/g' /etc/selinux/config
                    setenforce 0
                    #setting selinux Current mode: permissive
                    ######################################################
                    restorecon -vRF /opt/datasunrise/ > /dev/null
                    semanage port -a -t datasunrise_port_t -p tcp 11000-11010
                    semanage port -a -t datasunrise_port_t -p tcp $TRG_DBPORT
                    #semanage port -a -t datasunrise_port_t -p tcp $TRG_ADDITIONAL_INTERFACE_PORT
                    log "Adding ports to iptables"
                    iptables -A INPUT -p tcp --dport 11000:11010 -j ACCEPT
                    iptables -A INPUT -p tcp --dport $TRG_DBPORT -j ACCEPT
                    #iptables -A INPUT -p tcp --dport $TRG_ADDITIONAL_INTERFACE_PORT -j ACCEPT
                    service iptables save
                    # RHEL only ?
                    #log "Adding ports to firewalld"
                    #firewall-cmd --zone=drop --permanent --add-port=11000-11010/tcp
                    #firewall-cmd --zone=drop --permanent --add-port=$TRG_DBPORT/tcp
                    #firewall-cmd --zone=drop --permanent --add-port=$TRG_ADDITIONAL_INTERFACE_PORT/tcp
                    #systemctl restart firewalld
                    log "Setting sshd whitelist and blacklist"
                    echo 'ALL: '`echo $SSHADMINCIDR | cut -d"/" -f1`'/'`ipcalc $SSHADMINCIDR -m | cut -d"=" -f2` >> /etc/hosts.allow
                    sed -i 's/#ALL: ALL/ALL: ALL/g' /etc/hosts.deny
                    log "Turning on DataSunrise service"
                    systemctl enable datasunrise
                    log "Turn on DataSunrise daemon"
                    chkconfig datasunrise on
                    log "Setup $AF_GCNF..."
                    local AF_GCNF=/etc/datasunrise.conf
                    local ORACLE_HOME=/usr/lib/oracle/19.10/client64/lib
                    echo "DS_SERVER_NAME_PREFIX=ds" | tee -a $AF_GCNF
                    echo "AWS_PCODE=\"$AWS_AMI_PCODE\"" | tee -a $AF_GCNF
                    echo "ORACLE_HOME=$ORACLE_HOME" | tee -a $AF_GCNF
                    log "DS configuration file $AF_GCNF"
                    cat $AF_GCNF
                    if [ "$DSLICTYPE" == "BYOL" ]; then
                        log "Setup BYOL licensing model..."
                        setupDSLicense
                    else
                        log "Setup Hourly Billing licensing model..."
                        cp appfirewall-hb.reg /opt/datasunrise/appfirewall.reg
                    fi
                    makeItMine
                    #cleanLogs
                    cleanSQLite
                    logEndAct "Install DataSunrise result - $RETVAL"
                  }
              - {
                   DSCloudRoot: !FindInMap [Consts, V1, DSCloudRoot]
                }
              mode: '000755'
              owner: ec2-user
              group: ec2-user
            /opt/cooked/appfirewall-hb.reg:
              content: >-
                aT3Ma4BfGhCzDzhAerfmTq8yGS1Zwm4uLPio8Rv1CdDBhbwF0Lzwzh+aEyFaz+hoFnoqnwzDynZ8L4QRH1WDrg==:0:{"CustomerName":"aws","AWSMetering":"true"}
              mode: '000644'
              owner: ec2-user
              group: ec2-user
            /opt/cooked/ds-setup.sh:
              content: !Sub
              - |
                #!/bin/bash
                setInstallationType() {
                    logBeginAct "Setting up Installation Type for AWS..."
                    LD_LIBRARY_PATH="$DSROOT":"$DSROOT/lib":$LD_LIBRARY_PATH AF_HOME="$AF_HOME" AF_CONFIG="$AF_HOME" $DSROOT/AppBackendService \
                        CHANGE_SETTINGS=1 InstallationType=1
                    RETVAL=$?
                    logEndAct "Setting up Installation Type for AWS result - $RETVAL"
                }
                resetAdminPassword() {
                    logBeginAct "Reset Admin Password..."
                    LD_LIBRARY_PATH="$DSROOT":"$DSROOT/lib":$LD_LIBRARY_PATH AF_HOME="$AF_HOME" AF_CONFIG="$AF_HOME" $DSROOT/AppBackendService \
                        SET_ADMIN_PASSWORD=$DSAdminPassword
                    RETVAL=$?
                    echo $INST_CAPT: Reset DS Admin Password result - $RETVAL
                }
                resetDict() {
                    local HA_DBTYPE_LWR="`echo "$HA_DBTYPE" | tr '[:upper:]' '[:lower:]'`"
                    local HA_DBPASSWD="`aws --region $EC2REGION secretsmanager get-secret-value --secret-id $CFDEPLOYMENTNAME-secret-config-password --query SecretString --output text`"
                    logBeginAct "Reset Dictionary..."
                    LD_LIBRARY_PATH="$DSROOT":"$DSROOT/lib":$LD_LIBRARY_PATH AF_HOME="$AF_HOME" AF_CONFIG="$AF_HOME" $DSROOT/AppBackendService \
                        CLEAN_LOCAL_SETTINGS \
                        DICTIONARY_TYPE="$HA_DBTYPE_LWR" \
                        DICTIONARY_HOST="$HA_DBHOST" \
                        DICTIONARY_PORT="$HA_DBPORT" \
                        DICTIONARY_DB_NAME="$HA_DBNAME" \
                        DICTIONARY_LOGIN="$HA_DBUSER" \
                        DICTIONARY_PASS="$HA_DBPASSWD" \
                        FIREWALL_SERVER_NAME="$DS_SERVER" \
                        FIREWALL_SERVER_HOST="$DS_HOST_PRIVIP" \
                        FIREWALL_SERVER_BACKEND_PORT=11000 \
                        FIREWALL_SERVER_CORE_PORT=11001 \
                        FIREWALL_SERVER_BACKEND_HTTPS=1 \
                        FIREWALL_SERVER_CORE_HTTPS=1
                    RETVAL=$?
                    logEndAct "Reset DS Dictionary to $HA_DBHOST:$HA_DBPORT result - $RETVAL"
                }
                resetAudit() {
                    local HA_AUPASSWD="`aws --region $EC2REGION secretsmanager get-secret-value --secret-id $CFDEPLOYMENTNAME-secret-config-password --query SecretString --output text`"
                    logBeginAct "Reset Audit..."
                    LD_LIBRARY_PATH="$DSROOT":"$DSROOT/lib":$LD_LIBRARY_PATH AF_HOME="$AF_HOME" AF_CONFIG="$AF_HOME" $DSROOT/AppBackendService \
                        CHANGE_SETTINGS \
                        AuditDatabaseType="$HA_AUTYPE" \
                        AuditDatabaseHost="$HA_AUHOST" \
                        AuditDatabasePort="$HA_AUPORT" \
                        AuditDatabaseName="$HA_AUNAME" \
                        AuditLogin="$HA_AUUSER" \
                        AuditPassword="$HA_AUPASSWD"
                    RETVAL=$?
                    logEndAct "Reset DS Audit to $HA_AUHOST:$HA_AUPORT result - $RETVAL"
                }
                setupProxy() {
                    local TRG_DBPASSWD="`aws --region $EC2REGION secretsmanager get-secret-value --secret-id $CFDEPLOYMENTNAME-secret-tdb-password --query SecretString --output text`"
                    logBeginAct "Setup DS proxy $TRG_INSTNAME for $TDBHost:$TDBPort"
                    loginAsAdmin
                    if [ $RETVAL == 0 ]; then
                        local XTRA_ARGS=
                        local ENCRYPTION_ARGS=
                        if [ "$TRG_DBTYPE" = "Oracle" ]; then
                            XTRA_ARGS="-instance $TRG_DBNAME"
                        fi
                        if "$TRG_ENCRYPTION" && [[ "$TRG_DBTYPE" =~ ^(Aurora MySQL|MySQL|MariaDB|Cassandra|DB2|DynamoDB|MongoDB|Oracle|SAP HANA)$ ]]; then
                            ENCRYPTION_ARGS="-ssl"
                        fi
                        logBeginAct "addInstancePlus $TRG_INSTNAME..."
                        $DSROOT/cmdline/executecommand.sh addInstancePlus -name "$TRG_INSTNAME" $XTRA_ARGS\
                            -dbType "$TRG_DBTYPE" \
                            -dbHost "$TRG_DBHOST" \
                            -dbPort "$TRG_DBPORT" \
                            -database "$TRG_DBNAME" \
                            -login "$TRG_DBUSER" \
                            -password "$TRG_DBPASSWD" \
                            -proxyHost "$DS_HOST_PRIVIP" \
                            -proxyPort "$TRG_DBPORT" \
                            -savePassword ds \
                            $ENCRYPTION_ARGS
                        RETVAL=$?
                        if [ $RETVAL == 0 ]; then
                            logBeginAct "Add AuditRuleAdmin..."
                            $DSROOT/cmdline/executecommand.sh addRule -action audit -name AuditRuleAdmin -logData true -filterType ddl -ddlSelectAll true -dbType "$TRG_DBTYPE" -instance "$TRG_INSTNAME"
                            logBeginAct "Add AuditRuleDML..."
                            $DSROOT/cmdline/executecommand.sh addRule -action audit -name AuditRuleDML -logData true -dbType "$TRG_DBTYPE" -instance "$TRG_INSTNAME"
                            RETVAL=$?
                        fi
                    fi
                    RETVAL=$?
                    logEndAct "Setup DS proxy $TRG_INSTNAME for $TDBHost:$TDBPort result - $RETVAL"
                }
                copyProxy()
                {
                  logBeginAct "Starting copying proxies..."
                  service datasunrise stop
                  LD_LIBRARY_PATH="$DSROOT":"$DSROOT/lib":$LD_LIBRARY_PATH AF_HOME="$AF_HOME" AF_CONFIG="$AF_HOME" $DSROOT/AppBackendService COPY_PROXIES
                  LD_LIBRARY_PATH="$DSROOT":"$DSROOT/lib":$LD_LIBRARY_PATH AF_HOME="$AF_HOME" AF_CONFIG="$AF_HOME" $DSROOT/AppBackendService COPY_TRAILINGS
                  service datasunrise start
                  logEndAct "Finished copying proxies"
                }
                checkInstanceExists() {
                  logBeginAct "Checking existing instances..."
                  loginAsAdmin
                  local instances=`$DSROOT/cmdline/executecommand.sh showInstances`;
                    if [[ "$instances" == "No Instances" ]]; then
                      logEndAct "No instances found, returning 0."
                      return 0
                    else
                      logEndAct "Instances found, returning 1."
                      return 1
                    fi
                }
                checkNeigbrours()
                {
                  logBeginAct "Checking neigbour instances from my ASG..."
                  TOKEN=`curl -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 21600"`
                  INST_ID=`curl -s http://169.254.169.254/latest/meta-data/instance-id -H "X-aws-ec2-metadata-token: $TOKEN"`
                  local neigbours=$(aws ec2 describe-instances --filters 'Name=tag:aws:autoscaling:groupName,Values=${ASGName}' | python -c "import sys,json; [sys.stdout.write(str(inst)) for instance in json.load(sys.stdin)['Reservations'] for inst in instance['Instances'] if inst['InstanceId'] != '$INST_ID']")
                  if [[ -z $neigbours ]]; then
                    logEndAct "No neighbours found, returning 0"
                    return 0
                  else
                    logEndAct "Neigbours found, returning 1"
                    return 1
                  fi
                }
                waitForRandTime()
                {
                  logBeginAct "Waiting for random time..."
                  sleep $(( RANDOM % 270 + 30 ));
                  logEndAct "Finished waiting"
                }
                processSetupOrCopy()
                {
                  logBeginAct "Entered main setupProxy function. Will decide to create or to copy..."
                  checkInstanceExists
                  if [ $? == 1 ]; then
                    copyProxy
                  else
                    checkNeigbrours
                    if [ $? == 0 ]; then
                      setupProxy
                    else
                      waitForRandTime
                      checkInstanceExists
                      if [ $? == 1 ]; then
                        copyProxy
                      else
                        setupProxy
                        if [ $? -ne 0 ]; then
                          copyProxy
                        fi
                      fi
                    fi
                  fi
                  logEndAct "Exited main setupProxy function."
                }
                setupBackupParams() {
                    logBeginAct "Setup backups..."
                    loginAsAdmin
                    if [ $RETVAL == 0 ]; then
                        log "Setup OnDictionaryBackupDoneCommand..."
                        $DSROOT/cmdline/executecommand.sh changeParameter -name OnDictionaryBackupDoneCommand -value "$DSCLOUDDIR/backup-prepare.sh <backup_path> Dictionary"
                        log "Setup OnOldLogDeleteCommand..."
                        $DSROOT/cmdline/executecommand.sh changeParameter -name OnOldLogDeleteCommand -value "$DSCLOUDDIR/backup-prepare.sh <log_file>"
                        RETVAL=$?
                    fi
                    logEndAct "Setup backups result - $RETVAL"
                }
                setupBackupActions() {
                    echo -ne "*/5 * * * * root $DSCLOUDDIR/backup-upload.sh s3://$BackupS3BucketName\n" | tee --append /etc/crontab
                }
                setupAdditionals() {
                    logBeginAct "Setup additional parameters..."
                    loginAsAdmin
                    if [ $RETVAL == 0 ]; then
                        log "Setup WebLoadBalancerEnabled..."
                        $DSROOT/cmdline/executecommand.sh changeParameter -name WebLoadBalancerEnabled -value 1
                        log "Setup AuditDiscFreeSpaceLimit for HA config..."
                        $DSROOT/cmdline/executecommand.sh changeParameter -name AuditDiscFreeSpaceLimit -value 2048
                        log "Setup LogsDiscFreeSpaceLimit for HA config..."
                        $DSROOT/cmdline/executecommand.sh changeParameter -name LogsDiscFreeSpaceLimit -value 2048
                        log "Setup EnableAWSMetrics for HA config..."
                        $DSROOT/cmdline/executecommand.sh changeParameter -name EnableAWSMetrics -value 1
                        log "Setup LogTotalSizeCore for HA config..."
                        $DSROOT/cmdline/executecommand.sh changeParameter -name LogTotalSizeCore -value 10000
                        log "Setup LogTotalSizeBackend for HA config..."
                        $DSROOT/cmdline/executecommand.sh changeParameter -name LogTotalSizeBackend -value 10000
                        log "Setup AuditPartitionEnable for HA config..."
                        $DSROOT/cmdline/executecommand.sh changeParameter -name AuditPartitionEnable -value 1
                        log "Setup AuditPartitionInterval for HA config..."
                        $DSROOT/cmdline/executecommand.sh changeParameter -name AuditPartitionInterval -value 1
                        RETVAL=$?
                    fi
                    logEndAct "Setup additional parameters result - $RETVAL"
                }
                setupDSLicense() {
                    logBeginAct "Setup license..."
                    local DSLicenseKey="`aws --region $EC2REGION secretsmanager get-secret-value --secret-id $CFDEPLOYMENTNAME-secret-license-key --query SecretString --output text`"
                    if [ -z "$DSLicenseKey" ]; then
                        RETVAL=2
                        logEndAct "License key is EMPTY!"
                        return $RETVAL
                    fi
                    echo "$DSLicenseKey" > /tmp/appfirewall.reg
                    mv /tmp/appfirewall.reg $DSROOT/
                    makeItMineParam $DSROOT/appfirewall.pem
                    logEndAct "Setup license result - $?"
                }
                onAbortSetup() {
                    uploadAllSetupLogs
                    makeItMine
                    service datasunrise stop
                }
                setupCleaningTask() {
                    logBeginAct "Set node cleaning task..."
                    loginAsAdmin
                    if [ $RETVAL == 0 ]; then
                        local CLEANING_PT_JSON="{\"id\":-1,\"storePeriodType\":0,\"storePeriodValue\":0,\"name\":\"aws_remove_servers\",\"type\":18,\"lastExecTime\":\"\",\"nextExecTime\":\"\",\"lastSuccessTime\":\"\",\"lastErrorTime\":\"\",\"serverID\":0,\"forceUpdate\":false,\"params\":{},\"frequency\":{\"minutes\":{\"beginDate\":\"2018-09-28 00:00:00\",\"repeatEvery\":10}},\"updateNextExecTime\":true}"
                        $DSROOT/cmdline/executecommand.sh arbitrary -function updatePeriodicTask -jsonContent "$CLEANING_PT_JSON"
                        RETVAL=$?
                    fi
                    logEndAct "Set node cleaning task - $RETVAL"
                }
                runCleaningTask() {
                    logBeginAct "Run node cleaning task..."
                    loginAsAdmin
                    if [ $RETVAL == 0 ]; then
                        local EC2_CLEANING_TASK_ID=`$DSROOT/cmdline/executecommand.sh arbitrary -function getPeriodicTaskList -jsonContent "{taskTypes:[18]}" | python -c "import sys, json; print json.load(sys.stdin)['data'][1][0]"`
                        $DSROOT/cmdline/executecommand.sh arbitrary -function executePeriodicTaskManually -jsonContent "{id:$EC2_CLEANING_TASK_ID}"
                        RETVAL=$?
                    fi
                    logEndAct "Run node cleaning task - $RETVAL"
                }
                configureKeepAlive() {
                    echo "" >> /etc/sysctl.conf
                    echo "net.ipv4.tcp_keepalive_time = 60" | tee -a /etc/sysctl.conf
                    echo "net.ipv4.tcp_keepalive_intvl = 10" | tee -a /etc/sysctl.conf
                    echo "net.ipv4.tcp_keepalive_probes = 6" | tee -a /etc/sysctl.conf
                    sysctl -p -q 
                }
                createRDSKeyGroup() {
                    logBeginAct "Preparing RDS SSLKeyGroup..."
                    loginAsAdmin
                    $DSROOT/cmdline/executecommand.sh addSslKeyGroup -ca $DSROOT/rds-combined-ca-bundle.pem -name RDSGroup
                    logEndAct "RDS SSLKeyGroup created."
                }
                setupHttpProxy() {
                    local INP_STR=$AWSCLIProxy
                    PROXY_PROTO=${!INP_STR%://*}
                    PROXY_PROTO=${!PROXY_PROTO^^}
                    PROXY_URL=${!INP_STR#*://}
                    PROXY_USERPASS=${!PROXY_URL%@*}
                    if [ "$PROXY_USERPASS" == "$PROXY_URL" ]; then unset PROXY_USERPASS; fi
                    PROXY_PASSWD=${!PROXY_USERPASS#*:}
                    PROXY_HOSTPORT=${!PROXY_URL/"$PROXY_USERPASS"@/}
                    PROXY_PORT=${!PROXY_HOSTPORT#*:}
                    PROXY_HOST=${!PROXY_HOSTPORT/:"$PROXY_PORT"/}
                    if [ "$PROXY_PASSWD" == "$PROXY_USERPASS" ]; then
                        PROXY_USER=$PROXY_PASSWD
                        unset PROXY_PASSWD
                    else
                        PROXY_USER=${!PROXY_USERPASS/:"$PROXY_PASSWD"/}
                    fi
                    if [ "$PROXY_PROTO" == "HTTPS" ]; then
                        PROXY_PROTO_NUM=1
                    else
                        PROXY_PROTO_NUM=0
                    fi
                    logBeginAct "Setup HTTP proxy parameters..."
                    log "INP_STR      : $INP_STR"
                    log "PROXY_PROTO  : $PROXY_PROTO ($PROXY_PROTO_NUM)"
                    log "PROXY_HOST   : $PROXY_HOST"
                    log "PROXY_PORT   : $PROXY_PORT"
                    log "PROXY_USER   : $PROXY_USER"
                    log "PROXY_PASSWD : $PROXY_PASSWD"
                    $DSROOT/cmdline/executecommand.sh changeParameter -name HttpProxyType -value "$PROXY_PROTO_NUM"
                    $DSROOT/cmdline/executecommand.sh changeParameter -name HttpProxyHost -value "$PROXY_HOST"
                    $DSROOT/cmdline/executecommand.sh changeParameter -name HttpProxyPort -value "$PROXY_PORT"
                    if [ -n "$PROXY_USER" ]; then
                        $DSROOT/cmdline/executecommand.sh changeParameter -name HttpProxyUser -value "$PROXY_USER"
                    fi
                    if [ -n "$PROXY_PASSWD" ]; then
                        $DSROOT/cmdline/executecommand.sh changeParameter -name HttpProxyPassword -value "$PROXY_PASSWD"
                    fi
                    logEndAct "Setup HTTP proxy parameters result - $RETVAL"
                }
                configureJVM() {
                    logBeginAct "Configuring JVM..."
                    jvmpath=`find / -name libjvm.so`
                    echo $jvmpath | tr " " "\n" | sed -e "s/libjvm.so//" > /etc/ld.so.conf.d/jvm.conf
                    ldconfig
                    logEndAct "Configuring JVM result - $RETVAL"
                }
                prepareMsAudit() {
                    logBeginAct "Audit is MSSQL, preparing audit database..."
                    local HA_AUPASSWD="`aws --region $EC2REGION secretsmanager get-secret-value --secret-id $CFDEPLOYMENTNAME-secret-config-password --query SecretString --output text`"
                    logBeginAct "Preparing mssql database..."
                    cd /opt/mssql-tools/bin/
                    echo "CREATE DATABASE $HA_AUNAME;" > createdatabaseaudit.sql
                    echo "GO" >> createdatabaseaudit.sql
                    ./sqlcmd* -S $HA_AUHOST,$HA_AUPORT -U $HA_AUUSER -P $HA_AUPASSWD -i createdatabaseaudit.sql
                    rm createdatabaseaudit.sql
                    cd /opt/datasunrise 
                    logEndAct "Preparing audit database for MSSQL result - $RETVAL" 
                }
                prepareMsDictionary() {
                    logBeginAct "Dictionary is MSSQL, preparing dictionary database..."
                    local HA_DBPASSWD="`aws --region $EC2REGION secretsmanager get-secret-value --secret-id $CFDEPLOYMENTNAME-secret-config-password --query SecretString --output text`"
                    logBeginAct "Preparing mssql database..."
                    cd /opt/mssql-tools/bin/
                    echo "CREATE DATABASE $HA_DBNAME;" > createdatabasedictionary.sql
                    echo "GO" >> createdatabasedictionary.sql
                    #ONLY FOR MSSQL EXPRESS EDITION
                    echo "ALTER DATABASE $HA_DBNAME SET AUTO_CLOSE OFF;" >> createdatabasedictionary.sql
                    echo "GO" >> createdatabasedictionary.sql
                    ./sqlcmd* -S $HA_DBHOST,$HA_DBPORT -U $HA_DBUSER -P $HA_DBPASSWD -i createdatabasedictionary.sql
                    rm createdatabasedictionary.sql
                    cd /opt/datasunrise
                    logEndAct "Preparing dictonary database for MSSQL result - $RETVAL"
                }
                setcapAppFirewallCore() {
                    logBeginAct "Executing setcap on $DSROOT/AppFirewallCore"
                    DS_VER=$($DSROOT/AppBackendService VERSION)
                    DS_VER_MAJ=${!DS_VER:0:1}
                    DS_VER_MIN=${!DS_VER:2:1}
                    if [ $DS_VER_MAJ -ge 9 ]; then
                      log "No setcap required for $DS_VER"
                    elif  [ $DS_VER_MAJ -eq 8 ] && [ $DS_VER_MIN -ge 1 ]; then
                      log "No setcap required for $DS_VER"
                    else
                      log "Executing setcap"
                      setcap 'cap_net_raw,cap_net_admin=eip cap_net_bind_service=ep' $DSROOT/AppFirewallCore
                    fi
                    logEndAct "Execution finished. Exit code is - $?"
                }
                setDictionaryLicense()
                {
                    logBeginAct "Getting DS version"
                    local dsversion=`$DSROOT/AppBackendService VERSION`
                    logEndAct "Getting DS version done - $dsversion"
                    if [ '6.3.1.99999' = "`echo -e "6.3.1.99999\n$dsversion" | sort -V | head -n1`" ] ; then
                      logBeginAct "DS Version is higher than 6.3.1.99999: $dsversion, setting license to dictionary..."
                      LD_LIBRARY_PATH="$DSROOT":"$DSROOT/lib":$LD_LIBRARY_PATH AF_HOME="$AF_HOME" AF_CONFIG="$AF_HOME" $DSROOT/AppBackendService IMPORT_LICENSE_FROM_FILE=$DSROOT/appfirewall.reg
                      logEndAct "License has been set with exit code $?"
                    fi
                }
              - {
                    ASGName: !Join [ '', [!Ref DeploymentName, '-asg']]
                }
              mode: '000755'
              owner: ec2-user
              group: ec2-user
            /opt/cooked/datasunrise.fc:
              content: !Sub |
                /opt/datasunrise/AppBackendService        --    gen_context(system_u:object_r:datasunrise_exec_t,s0)
                /opt/datasunrise/AppFirewallCore        --    gen_context(system_u:object_r:datasunrise_exec_t,s0)
                /opt/datasunrise(/.*)?                gen_context(system_u:object_r:datasunrise_var_t,s0)
              mode: '000644'
              owner: ec2-user
              group: ec2-user
            /opt/cooked/datasunrise.if:
              content: !Sub |
                ## <summary>policy for datasunrise</summary>
                ########################################
                ## <summary>
                ##	Execute datasunrise_exec_t in the datasunrise domain.
                ## </summary>
                ## <param name="domain">
                ## <summary>
                ##	Domain allowed to transition.
                ## </summary>
                ## </param>
                #
                interface(`datasunrise_domtrans',`
                	gen_require(`
                		type datasunrise_t, datasunrise_exec_t;
                	')

                	corecmd_search_bin($1)
                	domtrans_pattern($1, datasunrise_exec_t, datasunrise_t)
                ')
                ######################################
                ## <summary>
                ##	Execute datasunrise in the caller domain.
                ## </summary>
                ## <param name="domain">
                ##	<summary>
                ##	Domain allowed access.
                ##	</summary>
                ## </param>
                #
                interface(`datasunrise_exec',`
                	gen_require(`
                		type datasunrise_exec_t;
                ')
                	corecmd_search_bin($1)
                	can_exec($1, datasunrise_exec_t)
                ')
              mode: '000644'
              owner: ec2-user
              group: ec2-user
            /opt/cooked/datasunrise.te:
              content: !Sub |
                policy_module(datasunrise, 1.0.1)
                ########################################
                # Declarations
                ########################################
                type datasunrise_t;
                type datasunrise_exec_t;
                init_daemon_domain(datasunrise_t, datasunrise_exec_t)
                type datasunrise_var_t;
                files_type(datasunrise_var_t)
                type datasunrise_port_t;
                corenet_port(datasunrise_port_t)
                #permissive datasunrise_t;
                require {
                    type cloud_init_t;
                    type rngd_t;
                    type systemd_logind_t;
                    type useradd_t;
                    type groupadd_t;
                	type bin_t;
                	type cgroup_t;
                	type cluster_port_t;
                	type commplex_main_port_t;
                	type ephemeral_port_t;
                	type fs_t;
                	type gear_port_t;
                	type gluster_port_t;
                	type hplip_port_t;
                	type http_port_t;
                	type keystone_port_t;
                	type ldap_port_t;
                	type mongod_port_t;
                	type mssql_port_t;
                	type mysqld_port_t;
                	type oracle_port_t;
                	type postgresql_port_t;
                	type proc_t;
                	type proc_net_t;
                	type random_device_t;
                	type shell_exec_t;
                	type smtp_port_t;
                	type sysctl_net_t;
                	type sysfs_t;
                	type tmp_t;
                	type tmpfs_t;
                	type unreserved_port_t;
                	type user_home_dir_t;
                	type user_t;
                	type usr_t;
                    class dbus { send_msg };
                	class chr_file { getattr open read };
                	class dir { add_name create getattr open read remove_name rmdir search setattr write };
                	class file { append create execute execute_no_trans getattr ioctl lock open read setattr unlink write };
                	class filesystem getattr;
                	class lnk_file read;
                	class netlink_socket create;
                	class packet_socket create;
                	class tcp_socket { listen name_bind name_connect };
                }
                ########################################
                allow datasunrise_t self:capability { setgid setuid };
                allow datasunrise_t self:fifo_file rw_fifo_file_perms;
                allow datasunrise_t self:netlink_socket create;
                allow datasunrise_t self:packet_socket create;
                allow datasunrise_t self:process { fork signal_perms };
                allow datasunrise_t self:tcp_socket { listen accept } ;
                allow datasunrise_t self:unix_stream_socket create_stream_socket_perms;
                ####################
                allow datasunrise_t bin_t:file { execute execute_no_trans };
                allow datasunrise_t cgroup_t:dir search;
                allow datasunrise_t cgroup_t:file { getattr open read };
                allow datasunrise_t cluster_port_t:tcp_socket name_connect;
                allow datasunrise_t commplex_main_port_t :tcp_socket { name_bind name_connect };
                allow datasunrise_t datasunrise_var_t:dir { add_name create getattr open read remove_name rmdir search write };
                allow datasunrise_t datasunrise_var_t:file { append create execute getattr lock open read unlink write };
                allow datasunrise_t datasunrise_port_t:tcp_socket { name_connect name_bind };
                allow datasunrise_t ephemeral_port_t:tcp_socket name_connect;
                allow datasunrise_t fs_t:filesystem getattr;
                allow datasunrise_t gear_port_t:tcp_socket name_connect;
                allow datasunrise_t gluster_port_t:tcp_socket name_connect;
                allow datasunrise_t hplip_port_t:tcp_socket { name_bind name_connect };
                allow datasunrise_t http_port_t:tcp_socket { name_bind name_connect };
                allow datasunrise_t keystone_port_t:tcp_socket name_connect;
                allow datasunrise_t ldap_port_t:tcp_socket name_connect;
                allow datasunrise_t mongod_port_t:tcp_socket { name_bind name_connect };
                allow datasunrise_t mssql_port_t:tcp_socket { name_bind name_connect };
                allow datasunrise_t mysqld_port_t:tcp_socket { name_bind name_connect };
                allow datasunrise_t oracle_port_t:tcp_socket { name_bind name_connect };
                allow datasunrise_t postgresql_port_t:tcp_socket { name_bind name_connect };
                allow datasunrise_t proc_t:file { getattr open read };
                allow datasunrise_t proc_net_t:file { getattr open read };
                allow datasunrise_t random_device_t:chr_file { getattr open read };
                allow datasunrise_t shell_exec_t:file execute;
                allow datasunrise_t smtp_port_t:tcp_socket name_connect;
                allow datasunrise_t sysctl_net_t:dir search;
                allow datasunrise_t sysctl_net_t:file { getattr open read };
                allow datasunrise_t sysfs_t:dir read;
                allow datasunrise_t sysfs_t:file { getattr open read };
                allow datasunrise_t sysfs_t:lnk_file read;
                allow datasunrise_t tmp_t:dir { add_name create read remove_name write };
                allow datasunrise_t tmp_t:file { create unlink write };
                allow datasunrise_t tmpfs_t:dir { add_name remove_name write };
                allow datasunrise_t tmpfs_t:file { create open read unlink write };
                allow datasunrise_t tmpfs_t:filesystem getattr;
                allow datasunrise_t unreserved_port_t:tcp_socket { name_bind name_connect };
                allow datasunrise_t user_home_dir_t:dir { add_name create getattr search setattr write };
                allow datasunrise_t user_home_dir_t:file { append create getattr ioctl lock open read setattr write };
                allow datasunrise_t usr_t:file { execute execute_no_trans };
                #============= datasunrise_t ==============
                allow datasunrise_t self:netlink_netfilter_socket create;
                #============= groupadd_t ==============
                allow groupadd_t usr_t:fifo_file write;
                #============= rngd_t ==============
                allow rngd_t cert_t:dir search;
                #============= systemd_logind_t ==============
                allow systemd_logind_t cloud_init_t:dbus send_msg;
                #============= useradd_t ==============
                allow useradd_t usr_t:fifo_file write;
                allow datasunrise_t self:process execmem;
                allow datasunrise_t user_home_dir_t:dir remove_name;
                allow datasunrise_t user_home_dir_t:file rename;
                ####################
                domain_use_interactive_fds(datasunrise_t)
                files_read_etc_files(datasunrise_t)
                auth_use_nsswitch(datasunrise_t)
                logging_send_syslog_msg(datasunrise_t)
                miscfiles_read_localization(datasunrise_t)
                sysnet_dns_name_resolve(datasunrise_t)
              mode: '000644'
              owner: ec2-user
              group: ec2-user
            /opt/cooked/scriptcron.sh:
              content: !Sub |
                #!/bin/bash
                DSCLOUDDIR=/opt/ds-cloud
                PYTHONDIR=/usr/bin
                LFNAME="$1"
                ASGNAME="$2"
                SECRETID="$3"
                TOKEN=`curl -X PUT "http://169.254.169.254/latest/api/token" -H "X-aws-ec2-metadata-token-ttl-seconds: 21600"`
                INST_ID=`curl -s http://169.254.169.254/latest/meta-data/instance-id -H "X-aws-ec2-metadata-token: $TOKEN"`
                INST_IP=`curl -s http://169.254.169.254/latest/meta-data/public-ipv4 -H "X-aws-ec2-metadata-token: $TOKEN"`
                chmod +x $DSCLOUDDIR/lifecyclehook.py
                source $DSCLOUDDIR/vm-creds.sh
                python3 -m pip install requests boto3
                $PYTHONDIR/python3 $DSCLOUDDIR/lifecyclehook.py $LFNAME $ASGNAME $INST_ID https://$INST_IP:11000 admin $SECRETID
              mode: '000755'
              owner: ec2-user
              group: ec2-user
            /opt/cooked/lifecyclehook.py:
              content: !Sub |
                #!/usr/bin/python3

                import itertools
                import random
                import base64
                import hashlib
                import urllib
                import requests
                import urllib3
                import time
                import boto3
                from sys import argv


                class RpcCrypto(object):
                    def __init__(self, session_id):
                        self._key = itertools.cycle(bytes([(session_id >> (8 * q)) & 0xff for q in range(0, 6)]))

                    def encrypt(self, password):
                        encrypted_password = bytes(a ^ b for (a, b) in zip(password.encode(), self._key))
                        trash_size = ((len(password) // 32 + 1) * 32) - len(password) - 1
                        trash = bytes(random.randint(1, 255) for _ in range(trash_size))
                        return base64.b64encode(encrypted_password + b'\x00' + trash).decode()

                    def decrypt(self, password):
                        decoded_password = base64.b64decode(password.encode())
                        decoded_real_password = decoded_password[0: decoded_password.rfind(0)]
                        decrypted_password = bytes(a ^ b for (a, b) in zip(decoded_real_password, self._key))
                        return decrypted_password.decode()


                if 3 / 2 != 1:
                    import urllib.parse

                    quote_plus = urllib.parse.quote_plus
                else:
                    quote_plus = urllib.quote_plus

                urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)


                class RestAPIClient(object):
                    def __init__(self):
                        self._session = requests.session()
                        self._cookie = None
                        self._session_id = -1
                        self._target_url = ''

                    def set_target_url(self, url):
                        self._target_url = url

                    def request_post(self, function_name, request, server_id=None, session_id=None):
                        if session_id is None:
                            session_id = self._session_id

                        request = {
                            "func": function_name,
                            "data": request,
                            "queryID": 1,
                            "session_id": session_id
                        }

                        if server_id is not None:
                            request["serverID"] = server_id

                        session = requests.session()
                        if self._cookie:
                            session.cookies.set_cookie(self._cookie)
                        response = session.post(self._target_url + "/web_iface", json=request, verify=False)
                        return response

                    def authorize(self, login, password):
                        init_connect_response = self.request_post("initConnect", {}, session_id=-1)
                        assertion_message = "Unable to authorize using given credentials"
                        assertion_message += "\n" + "error code: " + str(init_connect_response.status_code)
                        assertion_message += "\n" + "response:" + "\n" + str(init_connect_response.content)
                        assert init_connect_response.status_code == 200, assertion_message

                        is_ldap = True if init_connect_response.json()["auth_type"] == "LDAP" else False

                        secure_key = init_connect_response.json().get("secureKey")
                        session_id = init_connect_response.json().get("session_id")
                        self._session_id = session_id

                        password_hash_1 = hashlib.md5(password.encode('utf-8')).hexdigest()
                        password_hash_2 = hashlib.md5((password_hash_1 + secure_key).encode('utf-8')).hexdigest()

                        if is_ldap:
                            connect_response = self.request_post(
                                "connect", {"login": login, "hash": password_hash_2, "passwd": self.encrypt_password(password)},
                                session_id=session_id
                            )
                        else:
                            connect_response = self.request_post(
                                "connect", {"login": login, "hash": password_hash_2, "passwd": ""}, session_id=session_id
                            )

                        assertion_message = "Unable to authorize using given credentials"
                        assertion_message += "\n" + "error code: " + str(connect_response.status_code)
                        assertion_message += "\n" + "response:" + "\n" + str(connect_response.content)
                        assert connect_response.status_code == 200, assertion_message

                        error_code = connect_response.json()["error"]
                        error_desc = connect_response.json()["errorDesc"]
                        assert error_code == 0, error_desc

                        authorization_result = connect_response.json().get("res")
                        assert authorization_result, "Unable to authorize using given credentials"

                        self._cookie = requests.cookies.create_cookie("DS_SESSION", connect_response.cookies.get("DS_SESSION"))

                    def authorize_oauth2(self, token_request_url, client_id, client_secret, username, password):
                        def request_jwt_data():
                            jwt_request_session = requests.session()

                            authorization_hash = base64.b64encode(("%s:%s" % (client_id, client_secret)).encode()).decode()

                            jwt_request_session.headers["content-type"] = "application/x-www-form-urlencoded"
                            jwt_request_session.headers["accept"] = "application/json"
                            jwt_request_session.headers["authorization"] = "Basic %s" % authorization_hash

                            request_body = "grant_type=password"
                            request_body += "&username=%s&password=%s" % (
                                quote_plus(username), quote_plus(password),
                            )

                            jwt_response = jwt_request_session.post(
                                token_request_url,
                                data=request_body
                            )

                            assertion_message = "Unable to authorize using given credentials"
                            assertion_message += "\n" + "error code: " + str(jwt_response.status_code)
                            assertion_message += "\n" + "response:" + "\n" + str(jwt_response.content)
                            assert jwt_response.status_code == 200, assertion_message

                            jwt_response_json = jwt_response.json()
                            if "error" in jwt_response_json.keys():
                                assert False, jwt_response_json["error"]

                            return jwt_response_json

                        jwt_data = request_jwt_data()
                        # print("JWT:", jwt_data)
                        time.sleep(1)  # workaround

                        oauth2_connect_response = self.request_post(
                            "oauth2Connect", {"JWT": jwt_data}, session_id=-1
                        )
                        assertion_message = "Unable to authorize using given credentials"
                        assertion_message += "\n" + "error code: " + str(oauth2_connect_response.status_code)
                        assertion_message += "\n" + "response:" + "\n" + str(oauth2_connect_response.content)
                        assert oauth2_connect_response.status_code == 200, assertion_message

                        error_code = oauth2_connect_response.json()["error"]
                        error_desc = oauth2_connect_response.json()["errorDesc"]
                        assert error_code == 0, error_desc

                        authorization_result = oauth2_connect_response.json().get("res")
                        assert authorization_result, "Unable to authorize using given credentials"

                        self._cookie = requests.cookies.create_cookie("DS_SESSION", oauth2_connect_response.cookies.get("DS_SESSION"))
                        self._session_id = oauth2_connect_response.json().get("session_id")

                    def encrypt_password(self, password):
                        rpc_crypto = RpcCrypto(self._session_id)
                        encrypted_password = rpc_crypto.encrypt(password)

                        return encrypted_password

                    def decrypt_password(self, encrypted_password):
                        rpc_crypto = RpcCrypto(self._session_id)
                        password = rpc_crypto.decrypt(encrypted_password)

                        return password

                    @staticmethod
                    def parse_ds_table(table):
                        parsed_table = []
                        for row in table[1:]:
                            parsed_row = {}
                            for x in range(len(table[0])):
                                parsed_row[table[0][x]] = row[x]
                            parsed_table.append(parsed_row)

                        return parsed_table


                # --------------------------------------------------------------------------------

                life_cycle_hook, auto_scaling_group, instance_id, ds_url, ds_login, secret_id = argv[1:]

                # --------------------------------------------------------------------------------


                def get_password(secret_id):
                    secret_client = boto3.client('secretsmanager')
                    response = secret_client.get_secret_value(
                        SecretId=secret_id,
                    )['SecretString']
                    return response


                client = RestAPIClient()
                client.set_target_url(ds_url)
                client.authorize(ds_login, get_password(secret_id))


                def proxy_check():
                    proxy_status = client.request_post("getCoreObjectsStatus", {
                        "type": 8
                    }).json()

                    result_array = []
                    for i in proxy_status['objectsStatus']:
                        result_array.append(i['sessions'])

                    if result_array.count(0) != len(result_array):
                        return False
                    else:
                        return True
                # --------------------------------------------------------------------------------


                def abandon_lifecycle(life_cycle_hook, auto_scaling_group, instance_id):
                    asg_client = boto3.client('autoscaling')
                    asg_client.complete_lifecycle_action(
                        LifecycleHookName=life_cycle_hook,
                        AutoScalingGroupName=auto_scaling_group,
                        LifecycleActionResult='ABANDON',
                        InstanceId=instance_id
                        )


                def terminating_check(auto_scaling_group):
                    asg_client = boto3.client('autoscaling')
                    status = asg_client.describe_scaling_activities(
                        AutoScalingGroupName=auto_scaling_group,
                    )['Activities']
                    for activity in status:
                        if activity['StatusCode'] == 'MidTerminatingLifecycleAction' and activity['Description'] == 'Terminating EC2 instance: ' + instance_id:
                            return True
                    return False


                if terminating_check(auto_scaling_group):
                    if proxy_check():
                        print("Terminating instance")
                        abandon_lifecycle(life_cycle_hook, auto_scaling_group, instance_id)
                    else:
                        print("Connection with db is active")

              mode: '000755'
              owner: ec2-user
              group: ec2-user
    Properties:
      KeyName: !Ref VMKeyPair
      ImageId: !FindInMap 
        - RegionMap
        - !Ref 'AWS::Region'
        - AMI
      InstanceType: !Ref VMInstanceType
      SecurityGroups:
        - !Ref EC2SG
      IamInstanceProfile: !Ref DSNodeProfile
      InstanceMonitoring: !If 
        - HasAlarm
        - true
        - false
      BlockDeviceMappings:
        - DeviceName: /dev/sda1
          Ebs:
            DeleteOnTermination: true
            VolumeSize: 20
      MetadataOptions:
        HttpEndpoint: enabled
        HttpTokens: required
      UserData: 
        Fn::Base64: 
            !Sub 
            - |
              #!/bin/bash
              
              echo "CloudFormation script has been started"
              shopt -s extglob
              yum update -y -q
              
              CFS_BGN_TS=$(date +%s.%N)
              CFSTACKNAME=${AWS::StackName}
              CFDEPLOYMENTNAME=${DeploymentName}
              EC2REGION=${AWS::Region}
              DSROOT=${DSRoot}
              DSCLOUDDIR=${DSCloudRoot}
              mkdir -p $DSCLOUDDIR
              /opt/aws/bin/cfn-init -v --stack $CFSTACKNAME --resource DSLaunchConf --configsets AWSLinux1 --region $EC2REGION
              mv /opt/cooked/* $DSCLOUDDIR/
              rm -fR /opt/cooked
              AWS_STACK_ID_ARN=${AWS::StackId}
              AWS_STACK_ID="${!AWS_STACK_ID_ARN##*/}"
              echo "DSAdminPassword exporting has been started" 
              export DSAdminPassword=`aws --region $EC2REGION secretsmanager get-secret-value --secret-id $CFDEPLOYMENTNAME-secret-admin-password --query SecretString --output text`
              cd $DSCLOUDDIR
              
              # DO NOT change order!
              echo "vm-creds execution" 
              source vm-creds.sh
              echo "cf-params execution" 
              source cf-params.sh
              log "ds-manip execution" 
              source ds-manip.sh
              log "ds-setup execution" 
              source ds-setup.sh
              log "aws-ds-setup execution" 
              source aws-ds-setup.sh
              log "pre-setup execution" 
              source pre-setup.sh
              
              log "Setting up time zone" 
              mv /etc/localtime /etc/prev-localtime-bak
              timedatectl set-timezone "${timeZone}"
              
              log "Setting up Cloud Watch Alarm" 
              setupCloudWatch
              
              if [ -z "$AWS_DS_ID" ] ; then
                  log "No AD integration"
              else
                  logBeginAct "Start AD integration..." 
                  source ad-setup.sh

                  adGetInfo
                  if [ -z "$AWS_DS_NAME" ] ; then
                      log "Fetching AD info failed! No AD integration."
                  else
                      adSetupKerberos
                      adAddDNSToHosts
                      adSetupResolver
                      adJoin
                  fi
              fi
              
              if [ -z "$HA_DBHOST" ] || [ -z "$HA_DBPORT" ]; then
                  logEndAct "Dictionary RDS not found! Goodbye..."
                  onAbortSetup
                  exit $RETVAL
              fi
              if [ -z "$HA_AUHOST" ] || [ -z "$HA_AUPORT" ]; then
                  logEndAct "Audit RDS not found! Goodbye..."
                  onAbortSetup
                  exit $RETVAL
              fi
              installProduct
              if [ "$RETVAL" != "0" ]; then
                  logEndAct "Installation Error! Goodbye..."
                  onAbortSetup
                  exit $RETVAL
              fi
              # Installation OK, continue
              makeItMine
              logBeginAct "Setup DataSunrise..."
              cd $DSROOT
              FIRST_NODE=0
              if [ ${currentDictionaryType} == "MSSQL" ]; then
                  prepareMsDictionary
              fi
              resetDict
              setDictionaryLicense
              if [ "$RETVAL" == "93" ]; then
                  FIRST_NODE=1
                  logBeginAct "Setup First Node of DataSunrise..."
                  resetAdminPassword
              elif [ "$RETVAL" == "94" ]; then
                  FIRST_NODE=0
                  logBeginAct "Setup Next Node of DataSunrise..."
              else
                  logEndAct "Setup Dictionary Error! Goodbye..."
                  onAbortSetup
                  exit $RETVAL
              fi
              if [ ${currentAuditType} == "MSSQL" ]; then
                  prepareMsAudit
              fi
              resetAudit
              if [ "$RETVAL" != "96" ]; then
                  logEndAct "Setup Audit Error! Goodbye..."
                  onAbortSetup
                  exit $RETVAL
              fi
              setInstallationType
              makeItMine
              cleanLogs
              service datasunrise start
              sleep 20
              if [ "$FIRST_NODE" == "1" ]; then
                  setupProxy
                  setupCleaningTask
              else
                  processSetupOrCopy
                  runCleaningTask
              fi
              logEndAct "Create/copy proxy done - $?"
              if [ "$FIRST_NODE" == "1" ]; then
                  if [ -n "$BackupS3BucketName" ]; then
                      setupBackupParams
                  fi
                  if [ -n "$AWSCLIProxy" ]; then
                      setupHttpProxy
                  fi
                  setupAdditionals
              fi
              setupBackupActions
              service datasunrise stop
              makeItMine
              cleanLogs
              configureKeepAlive
              configureJVM
              setcapAppFirewallCore
              service datasunrise start
              CFS_END_TS=$(date +%s.%N)
              CFS_ELLAPSED=$(echo "$CFS_END_TS - $CFS_BGN_TS" | bc)
              logEndAct "Setup DataSunrise finished in $CFS_ELLAPSED sec."
              uploadSetupLogs
              setupCWLogUploading
              logBeginAct "Fixfiles..."
              fixfiles -FB onboot
              logEndAct "Fixfiles done - $?"
              logBeginAct "SElinux summary:"
              ausearch -m AVC -ts recent
              logEndAct "SElinux summary done - $?"
              echo -ne "*/1 * * * * root $DSCLOUDDIR/scriptcron.sh ${LFName} ${ASGName} ${SecretId}\n" | tee --append /etc/crontab
            - {
                  SecretId: !Join ['',[!Ref DeploymentName, '-secret-admin-password']],
                  LFName: !Join ['', [!Ref DeploymentName, '-hook']],
                  ASGName: !Join [ '', [!Ref DeploymentName, '-asg']],
                  DSCloudRoot: !FindInMap [Consts, V1, DSCloudRoot],
                  DSRoot: !FindInMap [Consts, V1, DSRoot],
                  currentAuditType: !Ref AuditType,
                  currentDictionaryType: !Ref DictionaryType,
                  timeZone: !Ref TimeZone
              }
  DSAutoScalingGroup:
    Type: 'AWS::AutoScaling::AutoScalingGroup'
    DependsOn:
      - DSLaunchConf
      - DSLoadBalancer
    Properties:
      AutoScalingGroupName: !Join [ '', [!Ref DeploymentName, '-asg']]
      LaunchConfigurationName: !Ref DSLaunchConf
      TargetGroupARNs:
        - !Ref DSWebUITargetGroup
        - !Ref DSTDBTargetGroup
      MinSize: !Ref EC2Count
      MaxSize: !Ref EC2Count
      VPCZoneIdentifier: !Ref SubnetsASGLB
      Cooldown: '120'
      HealthCheckType: !Ref AHealthCheckType
      HealthCheckGracePeriod: '600'
      Tags:
        - Key: Name
          Value: !Join ['', [!Ref DeploymentName, '-vm']]
          PropagateAtLaunch: 'True'
  DSAutoScalingPolicy:
    Type: 'AWS::AutoScaling::ScalingPolicy'
    Properties:
      AutoScalingGroupName: !Ref DSAutoScalingGroup
      EstimatedInstanceWarmup: '90'
      PolicyType: TargetTrackingScaling
      TargetTrackingConfiguration:
        PredefinedMetricSpecification:
          PredefinedMetricType: ASGAverageCPUUtilization
        TargetValue: '80'
  DSLifecycleHook:
    Type: 'AWS::AutoScaling::LifecycleHook'
    DependsOn:
      - DSAutoScalingGroup
    Properties:
      AutoScalingGroupName: !Join [ '', [!Ref DeploymentName, '-asg']]
      LifecycleHookName: !Join ['', [!Ref DeploymentName, '-hook']]
      LifecycleTransition: 'autoscaling:EC2_INSTANCE_TERMINATING'
      HeartbeatTimeout: 7200
Outputs:
  DatasunriseConsoleURL:
    Description: Click to proceed to the DataSunrise Console
    Value: !Join ['', ['https://', !GetAtt DSLoadBalancer.DNSName, ':11000/v2']]
  ELBProxyEndpoint:
    Description: >-
      Replace database hostname with this value to start using DataSunrise
      Firewall mode
    Value: !GetAtt DSLoadBalancer.DNSName
  ELBProxyPort:
    Description: >-
      Replace database port with this value to start using DataSunrise Firewall
      in HA mode
    Value: !Ref TDBPort
  SecurityGroupId:
    Description: Security group ID
    Value: !GetAtt EC2SG.GroupId
  SecurityGroupVpcId:
    Description: Security group VPC ID
    Value: !GetAtt EC2SG.VpcId
  SecurityGroupUrl:
    Description: Security group url
    Value: !Join ['', ['https://console.aws.amazon.com/ec2/v2/home?region=', !Ref 'AWS::Region', '#SecurityGroups:search=', !GetAtt EC2SG.GroupId, ';sort=groupId']]
